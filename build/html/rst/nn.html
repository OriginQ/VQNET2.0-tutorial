

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>经典神经网络模块 &mdash; VQNET v2.15.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/documentation_options.js?v=a149e6fc"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="实用函数" href="utils.html" />
    <link rel="prev" title="QTensor 模块" href="QTensor.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            VQNET
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">安装介绍</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">VQNet 安装步骤</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">上手实例</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vqc_demo.html">使用自动微分模拟的量子机器学习示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="qml_demo.html">使用pyQPanda2的量子机器学习示例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">经典神经网络接口介绍</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="QTensor.html">QTensor 模块</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">经典神经网络模块</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">基本例子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cpu">CPU下模型训练</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gpu">GPU下模型训练</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module">Module类</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">Module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.Module"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.Module</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#forward">forward</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.Module.forward"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.Module.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#state-dict">state_dict</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.Module.state_dict"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.Module.state_dict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#togpu">toGPU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.Module.toGPU"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.Module.toGPU()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tocpu">toCPU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.Module.toCPU"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.Module.toCPU()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#save-parameters">模型参数保存和载入</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">save_parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.storage.save_parameters"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.storage.save_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#load-parameters">load_parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.storage.load_parameters"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.storage.load_parameters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#modulelist">ModuleList</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.ModuleList"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.ModuleList</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#parameterlist">ParameterList</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.ParameterList"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.ParameterList</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sequential">Sequential</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.module.Sequential"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.module.Sequential</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id6">经典神经网络层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#conv1d">Conv1D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Conv1D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Conv1D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#conv2d">Conv2D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Conv2D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Conv2D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#convt2d">ConvT2D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.ConvT2D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.ConvT2D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#avgpool1d">AvgPool1D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.AvgPool1D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.AvgPool1D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#maxpool1d">MaxPool1D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.MaxPool1D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.MaxPool1D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#avgpool2d">AvgPool2D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.AvgPool2D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.AvgPool2D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#maxpool2d">MaxPool2D</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.MaxPool2D"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.MaxPool2D</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#embedding">Embedding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.embedding.Embedding"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.embedding.Embedding</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#batchnorm2d">BatchNorm2d</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.BatchNorm2d"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.BatchNorm2d</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#batchnorm1d">BatchNorm1d</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.BatchNorm1d"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.BatchNorm1d</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#layernormnd">LayerNormNd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNormNd"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.layer_norm.LayerNormNd</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#layernorm2d">LayerNorm2d</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNorm2d"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.layer_norm.LayerNorm2d</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#layernorm1d">LayerNorm1d</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNorm1d"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.layer_norm.LayerNorm1d</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#groupnorm">GroupNorm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.group_norm.GroupNorm"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.group_norm.GroupNorm</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#linear">Linear</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Linear"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Linear</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dropout">Dropout</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.dropout.Dropout"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.dropout.Dropout</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#droppath">DropPath</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.dropout.DropPath"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.dropout.DropPath</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pixel-shuffle">Pixel_Shuffle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.pixel_shuffle.Pixel_Shuffle"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.pixel_shuffle.Pixel_Shuffle</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pixel-unshuffle">Pixel_Unshuffle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.pixel_shuffle.Pixel_Unshuffle"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.pixel_shuffle.Pixel_Unshuffle</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#gru">GRU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.gru.GRU"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.gru.GRU</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rnn">RNN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.rnn.RNN"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.rnn.RNN</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#lstm">LSTM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.lstm.LSTM"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.lstm.LSTM</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-gru">Dynamic_GRU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.gru.Dynamic_GRU"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.gru.Dynamic_GRU</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-rnn">Dynamic_RNN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.rnn.Dynamic_RNN"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.rnn.Dynamic_RNN</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-lstm">Dynamic_LSTM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.lstm.Dynamic_LSTM"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.lstm.Dynamic_LSTM</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#interpolate">Interpolate</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Interpolate"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Interpolate</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#fuse-module">fuse_module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.fuse_module"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.fuse_module</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sdpa">SDPA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.transformer.SDPA"><code class="docutils literal notranslate"><span class="pre">pyvqnet.transformer.SDPA</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id7">损失函数层</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#meansquarederror">MeanSquaredError</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.MeanSquaredError"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.MeanSquaredError</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#binarycrossentropy">BinaryCrossEntropy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.BinaryCrossEntropy"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.BinaryCrossEntropy</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#categoricalcrossentropy">CategoricalCrossEntropy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.CategoricalCrossEntropy"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.CategoricalCrossEntropy</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#softmaxcrossentropy">SoftmaxCrossEntropy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.SoftmaxCrossEntropy"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.SoftmaxCrossEntropy</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#nll-loss">NLL_Loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.NLL_Loss"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.NLL_Loss</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#crossentropyloss">CrossEntropyLoss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.CrossEntropyLoss"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.CrossEntropyLoss</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id8">激活函数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#activation">Activation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.activation.Activation"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.activation.Activation</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sigmoid">Sigmoid</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Sigmoid"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Sigmoid</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#softplus">Softplus</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Softplus"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Softplus</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#softsign">Softsign</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Softsign"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Softsign</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#softmax">Softmax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Softmax"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Softmax</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hardsigmoid">HardSigmoid</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.HardSigmoid"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.HardSigmoid</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#relu">ReLu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.ReLu"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.ReLu</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#leakyrelu">LeakyReLu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.LeakyReLu"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.LeakyReLu</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#gelu">Gelu</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Gelu"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Gelu</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#elu">ELU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.ELU"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.ELU</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tanh">Tanh</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.nn.Tanh"><code class="docutils literal notranslate"><span class="pre">pyvqnet.nn.Tanh</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id9">优化器模块</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#optimizer">Optimizer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.optimizer.Optimizer"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.optimizer.Optimizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#adadelta">Adadelta</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.adadelta.Adadelta"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.adadelta.Adadelta</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#adagrad">Adagrad</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.adagrad.Adagrad"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.adagrad.Adagrad</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#adam">Adam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.adam.Adam"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.adam.Adam</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#adamw">AdamW</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.adam.AdamW"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.adam.AdamW</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#adamax">Adamax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.adamax.Adamax"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.adamax.Adamax</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rmsprop">RMSProp</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.rmsprop.RMSProp"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.rmsprop.RMSProp</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sgd">SGD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.optim.sgd.SGD"><code class="docutils literal notranslate"><span class="pre">pyvqnet.optim.sgd.SGD</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#rotosolve">Rotosolve</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id11">指标模块</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mse">MSE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.MSE"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.MSE</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rmse">RMSE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.RMSE"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.RMSE</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#mae">MAE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.MAE"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.MAE</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#r-square">R_Square</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.R_Square"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.R_Square</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#precision-recall-f1-2-score">precision_recall_f1_2_score</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_2_score"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.precision_recall_f1_2_score</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#precision-recall-f1-n-score">precision_recall_f1_N_score</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_N_score"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.precision_recall_f1_N_score</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#precision-recall-f1-multi-score">precision_recall_f1_Multi_score</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_Multi_score"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.precision_recall_f1_Multi_score</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#auc-calculate">auc_calculate</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.utils.metrics.auc_calculate"><code class="docutils literal notranslate"><span class="pre">pyvqnet.utils.metrics.auc_calculate</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#vqnet">VQNet原生分布式计算模块</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id12">环境部署</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mpi">MPI安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nccl">NCCL安装</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">节点间通信环境部署</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id14">分布式启动</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#n-np">n, np</a></li>
<li class="toctree-l4"><a class="reference internal" href="#h-hosts">H, hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hostfile-f-hostfile">hostfile, f, hostfile</a></li>
<li class="toctree-l4"><a class="reference internal" href="#output-filename">output-filename</a></li>
<li class="toctree-l4"><a class="reference internal" href="#verbose">verbose</a></li>
<li class="toctree-l4"><a class="reference internal" href="#start-timeout">start-timeout</a></li>
<li class="toctree-l4"><a class="reference internal" href="#h">h</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#commcontroller">CommController</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.ControllComm.CommController</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#split-data">split_data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.datasplit.split_data"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.datasplit.split_data()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#get-local-rank">get_local_rank</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.get_local_rank"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.ControllComm.get_local_rank()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#get-rank">get_rank</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.get_rank"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.ControllComm.get_rank()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#init-group">init_group</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.init_group"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.ControllComm.init_group()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pipelineparalleltrainingwrapper">PipelineParallelTrainingWrapper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.pp.PipelineParallelTrainingWrapper"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.pp.PipelineParallelTrainingWrapper</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#zeromodelinitial">ZeroModelInitial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.ZeroModelInitial"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.ZeroModelInitial</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#columnparallellinear">ColumnParallelLinear</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.ColumnParallelLinear"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.ColumnParallelLinear</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#rowparallellinear">RowParallelLinear</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#pyvqnet.nn.pyvqnet.distributed.RowParallelLinear"><code class="docutils literal notranslate"><span class="pre">pyvqnet.distributed.RowParallelLinear</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">实用函数</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">使用pyqpanda的量子神经网络接口</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="qnn.html">使用pyQPanda2量子机器学习模块</a></li>
<li class="toctree-l1"><a class="reference internal" href="qnn_pq3.html">使用pyQPanda3量子机器学习模块</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">量子神经网络自动微分模拟接口</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vqc.html">变分量子线路自动微分模拟</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">量子大模型微调</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="llm.html">量子大模型微调示例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">其他</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torch_api.html">VQNet使用torch进行底层计算</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="CHANGELOG.html">VQNet Changelog</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">VQNET</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">经典神经网络模块</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/rst/nn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>经典神经网络模块<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h1>
<section id="id2">
<h2>基本例子<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<section id="cpu">
<h3>CPU下模型训练<a class="headerlink" href="#cpu" title="Link to this heading">¶</a></h3>
<p>以下的经典神经网络模块均支持自动反向传播计算。当您运行前传函数以后,再执行反向函数就可以计算梯度。一个卷积层的简单例子如下:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">arange</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kfloat32</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>

<span class="c1"># an image feed into two dimension convolution layer</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">2</span>        <span class="c1"># batch size</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">2</span>       <span class="c1"># input channels</span>
<span class="n">oc</span> <span class="o">=</span> <span class="mi">2</span>      <span class="c1"># output channels</span>
<span class="n">hw</span> <span class="o">=</span> <span class="mi">4</span>      <span class="c1"># input width and heights</span>

<span class="c1"># two dimension convolution layer</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">ic</span><span class="p">,</span><span class="n">oc</span><span class="p">,(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

<span class="c1"># input of shape [b,ic,hw,hw]</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">*</span><span class="n">ic</span><span class="o">*</span><span class="n">hw</span><span class="o">*</span><span class="n">hw</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">kfloat32</span><span class="p">)</span>

<span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">hw</span><span class="p">,</span><span class="n">hw</span><span class="p">])</span>

<span class="c1">#forward function</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>

<span class="c1">#backward function with autograd</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x0</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="c1"># [-0.0008376 -0.2780731 -0.0008376 -0.2780731  0.1125833  0.2805848</span>
<span class="c1">#   0.1125833  0.2805848 -0.0008376 -0.2780731 -0.0008376 -0.2780731</span>
<span class="c1">#   0.1125833  0.2805848  0.1125833  0.2805848  0.5759128 -0.057339</span>
<span class="c1">#   0.5759128 -0.057339  -0.342508  -0.4853693 -0.342508  -0.4853693</span>
<span class="c1">#   0.5759128 -0.057339   0.5759128 -0.057339  -0.342508  -0.4853693</span>
<span class="c1">#  -0.342508  -0.4853693 -0.0008376 -0.2780731 -0.0008376 -0.2780731</span>
<span class="c1">#   0.1125833  0.2805848  0.1125833  0.2805848 -0.0008376 -0.2780731</span>
<span class="c1">#  -0.0008376 -0.2780731  0.1125833  0.2805848  0.1125833  0.2805848</span>
<span class="c1">#   0.5759128 -0.057339   0.5759128 -0.057339  -0.342508  -0.4853693</span>
<span class="c1">#  -0.342508  -0.4853693  0.5759128 -0.057339   0.5759128 -0.057339</span>
<span class="c1">#  -0.342508  -0.4853693 -0.342508  -0.4853693]</span>
</pre></div>
</div>
</section>
<section id="gpu">
<h3>GPU下模型训练<a class="headerlink" href="#gpu" title="Link to this heading">¶</a></h3>
<p>您需要安装linux版本下的pyvqnet才能使用GPU。需要保证数据QTensor以及Module均在GPU上。可使用 <cite>toGPU</cite> 转移数据或者 <cite>gpu</cite> 创建副本,或者在数据创建函数中使用device指定。</p>
<p>请参考以下例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">arange</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kfloat32</span><span class="p">,</span><span class="n">DEV_GPU_0</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>


<span class="n">b</span> <span class="o">=</span> <span class="mi">2</span>        <span class="c1"># batch size</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">2</span>       <span class="c1"># input channels</span>
<span class="n">oc</span> <span class="o">=</span> <span class="mi">2</span>      <span class="c1"># output channels</span>
<span class="n">hw</span> <span class="o">=</span> <span class="mi">4</span>      <span class="c1"># input width and heights</span>


<span class="n">test_conv</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">ic</span><span class="p">,</span><span class="n">oc</span><span class="p">,(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="c1">#复制到gpu上DEV_GPU_0</span>
<span class="n">test_conv</span><span class="o">.</span><span class="n">toGPU</span><span class="p">(</span><span class="n">DEV_GPU_0</span><span class="p">)</span>
<span class="c1"># input of shape [b,ic,hw,hw]</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">*</span><span class="n">ic</span><span class="o">*</span><span class="n">hw</span><span class="o">*</span><span class="n">hw</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">kfloat32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="n">hw</span><span class="p">,</span><span class="n">hw</span><span class="p">])</span>

<span class="c1">#使用gpu 复制数据到DEV_GPU_0,亦可以在函数内指定ID,也可以使用相关tensor接口的device进行指定</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">GPU</span><span class="p">(</span><span class="n">DEV_GPU_0</span><span class="p">)</span>
<span class="n">x0</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1">#forward function</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">test_conv</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="c1">#backward function with autograd</span>
<span class="n">x</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x0</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="module">
<h2>Module类<a class="headerlink" href="#module" title="Link to this heading">¶</a></h2>
<p>abstract calculation module</p>
<section id="id3">
<h3>Module<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.Module">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.</span></span><span class="sig-name descname"><span class="pre">Module</span></span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.Module" title="Link to this definition">¶</a></dt>
<dd><p>所有神经网络模块的基类,包括量子模块或经典模块。您的模型也应该是此类的子类,用于 autograd 计算。
模块还可以包含其他Module类,允许将它们嵌套在树状结构。 您可以将子模块分配为常规属性:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>以这种方式分配的子模块将被注册。</p>
</dd></dl>

</section>
<section id="forward">
<h3>forward<a class="headerlink" href="#forward" title="Link to this heading">¶</a></h3>
<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.Module.forward">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.Module.</span></span><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.Module.forward" title="Link to this definition">¶</a></dt>
<dd><p>Module类抽象前向计算函数</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – 输入QTensor。</p></li>
<li><p><strong>*args</strong> – 非关键字可变参数。</p></li>
<li><p><strong>**kwargs</strong> – 关键字可变参数。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>模型输出。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">vq</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">oc</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">ic</span><span class="p">,</span> <span class="n">oc</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span> <span class="o">*</span> <span class="n">ic</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">ic</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">vq</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[4.3995643, 3.9317808, -2.0707254],</span>
<span class="c1">#  [20.1951981, 21.6946659, 14.2591858],</span>
<span class="c1">#  [38.4702759, 31.9730244, 24.5977650]],</span>
<span class="c1"># [[-17.0607567, -31.5377998, -7.5618000],</span>
<span class="c1">#  [-22.5664024, -40.3876266, -15.1564388],</span>
<span class="c1">#  [-3.1080279, -18.5986233, -8.0648050]]],</span>
<span class="c1"># [[[6.6493244, -13.4840755, -20.2554188],</span>
<span class="c1">#  [54.4235802, 34.4462433, 26.8171902],</span>
<span class="c1">#  [90.2827682, 62.9092331, 51.6892929]],</span>
<span class="c1"># [[-22.3385429, -45.2448578, 5.7101378],</span>
<span class="c1">#  [-32.9464149, -60.9557228, -10.4994345],</span>
<span class="c1">#  [5.9029331, -20.5480480, -0.9379558]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="state-dict">
<h3>state_dict<a class="headerlink" href="#state-dict" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.Module.state_dict">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.Module.</span></span><span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.Module.state_dict" title="Link to this definition">¶</a></dt>
<dd><p>返回包含模块整个状态的字典:包括参数和缓存值。
键是对应的参数和缓存值名称。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> – 返回保存模型内部模块,参数的字典。</p></li>
<li><p><strong>prefix</strong> – 使用的参数和缓存值的命名前缀。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>包含模块整个状态的字典。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_conv</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="c1">#odict_keys([&#39;weights&#39;, &#39;bias&#39;])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="togpu">
<h3>toGPU<a class="headerlink" href="#togpu" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.Module.toGPU">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.Module.</span></span><span class="sig-name descname"><span class="pre">toGPU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">DEV_GPU_0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.Module.toGPU" title="Link to this definition">¶</a></dt>
<dd><p>将模块和其子模块的参数和缓冲数据移动到指定的 GPU 设备中。</p>
<p>device 指定存储其内部数据的设备。 当device &gt;= DEV_GPU_0时,数据存储在GPU上。如果您的计算机有多个GPU,
则可以指定不同的设备来存储数据。例如device = DEV_GPU_1 , DEV_GPU_2, DEV_GPU_3, … 表示存储在不同序列号的GPU上。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Module在不同GPU上无法进行计算。
如果您尝试在 ID 超过验证 GPU 最大数量的 GPU 上创建 QTensor,将引发 Cuda 错误。</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – 当前保存QTensor的设备,默认:DEV_GPU_0。device= pyvqnet.DEV_GPU_0,存储在第一个 GPU 中,devcie = DEV_GPU_1,存储在第二个 GPU 中,依此类推</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Module 移动到 GPU 设备。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.conv</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvT2D</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">ConvT2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_conv</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
<span class="c1">#1000</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="tocpu">
<h3>toCPU<a class="headerlink" href="#tocpu" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.Module.toCPU">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.Module.</span></span><span class="sig-name descname"><span class="pre">toCPU</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.Module.toCPU" title="Link to this definition">¶</a></dt>
<dd><p>将模块和其子模块的参数和缓冲数据移动到特定的 CPU 设备中。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Module 移动到 CPU 设备。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.conv</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvT2D</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">ConvT2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">toCPU</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_conv</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
<span class="c1">#0</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="save-parameters">
<span id="id4"></span><h2>模型参数保存和载入<a class="headerlink" href="#save-parameters" title="Link to this heading">¶</a></h2>
<p>以下接口可以进行模型参数保存到文件中,或从文件中读取参数文件。但请注意,文件中不保存模型结构,需要用户手动构建模型结构。</p>
<section id="id5">
<h3>save_parameters<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.storage.save_parameters">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.storage.</span></span><span class="sig-name descname"><span class="pre">save_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.storage.save_parameters" title="Link to this definition">¶</a></dt>
<dd><p>保存模型参数的字典到一个文件。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obj</strong> – 需要保存的字典。</p></li>
<li><p><strong>f</strong> – 保存参数的文件名。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>无。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span><span class="n">Conv2D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Net</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">pyvqnet</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">save_parameters</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="s2">&quot;tmp.model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="load-parameters">
<h3>load_parameters<a class="headerlink" href="#load-parameters" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.storage.load_parameters">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.storage.</span></span><span class="sig-name descname"><span class="pre">load_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">f</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.storage.load_parameters" title="Link to this definition">¶</a></dt>
<dd><p>从文件中载入参数到一个字典中。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>f</strong> – 保存参数的文件名。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>保存参数的字典。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">Conv2D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>


<span class="k">class</span><span class="w"> </span><span class="nc">Net</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">output_channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                            <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                            <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>  <span class="c1"># another Module object</span>
<span class="n">pyvqnet</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">save_parameters</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;tmp.model&quot;</span><span class="p">)</span>
<span class="n">model_para</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">load_parameters</span><span class="p">(</span><span class="s2">&quot;tmp.model&quot;</span><span class="p">)</span>
<span class="n">model1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_para</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="modulelist">
<h2>ModuleList<a class="headerlink" href="#modulelist" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.ModuleList">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.</span></span><span class="sig-name descname"><span class="pre">ModuleList</span></span><span class="sig-paren">(</span><span class="optional">[</span><em class="sig-param"><span class="n"><span class="pre">pyvqnet.nn.module.Module</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.ModuleList" title="Link to this definition">¶</a></dt>
<dd><p>将子模块保存在列表中。 ModuleList 可以像普通的 Python 列表一样被索引, 它包含的Module的内部参数等可以被保存起来。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>modules</strong> – nn.Modules 列表</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个模块列表</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span><span class="n">Linear</span><span class="p">,</span><span class="n">ModuleList</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.qnn</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProbsMeasure</span><span class="p">,</span><span class="n">QuantumLayer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyqpanda</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pqctest</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">param</span><span class="p">,</span><span class="n">qubits</span><span class="p">,</span><span class="n">cubits</span><span class="p">,</span><span class="n">m_machine</span><span class="p">):</span>
    <span class="n">circuit</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">QCircuit</span><span class="p">()</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">H</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">H</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">H</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">H</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>

    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="nb">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="nb">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="nb">input</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>

    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">qubits</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="n">param</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">qubits</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">qubits</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>
    <span class="c1">#print(circuit)</span>

    <span class="n">prog</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">QProg</span><span class="p">()</span>
    <span class="n">prog</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">circuit</span><span class="p">)</span>

    <span class="n">rlt_prob</span> <span class="o">=</span> <span class="n">ProbsMeasure</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="n">prog</span><span class="p">,</span><span class="n">m_machine</span><span class="p">,</span><span class="n">qubits</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rlt_prob</span>


<span class="k">class</span><span class="w"> </span><span class="nc">M</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pqc2</span> <span class="o">=</span> <span class="n">ModuleList</span><span class="p">([</span><span class="n">QuantumLayer</span><span class="p">(</span><span class="n">pqctest</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pqc2</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>  <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pqc2</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">mm</span> <span class="o">=</span> <span class="n">M</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mm</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="c1">#odict_keys([&#39;pqc2.0.m_para&#39;, &#39;pqc2.1.weights&#39;, &#39;pqc2.1.bias&#39;])</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="parameterlist">
<h2>ParameterList<a class="headerlink" href="#parameterlist" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.ParameterList">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.</span></span><span class="sig-name descname"><span class="pre">ParameterList</span></span><span class="sig-paren">(</span><span class="optional">[</span><em class="sig-param"><span class="n"><span class="pre">pyvqnet.nn.module.Module</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.ParameterList" title="Link to this definition">¶</a></dt>
<dd><p>将参数保存在列表中, ParameterList 可以像普通的 Python 列表一样被索引, 它包含的Parameter的内部参数等可以被保存起来。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>modules</strong> – nn.Parameter 列表</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个参数列表</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

        <span class="c1"># ParameterList can act as an iterable, or be indexed using ints</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">p</span> <span class="o">*</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="sequential">
<h2>Sequential<a class="headerlink" href="#sequential" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.module.Sequential">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.module.</span></span><span class="sig-name descname"><span class="pre">Sequential</span></span><span class="sig-paren">(</span><span class="optional">[</span><em class="sig-param"><span class="n"><span class="pre">pyvqnet.nn.module.Module</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.module.Sequential" title="Link to this definition">¶</a></dt>
<dd><p>模块将按照传递的顺序添加模块。或者,也可以将模块的 <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> 传入。<code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 的 <code class="docutils literal notranslate"><span class="pre">forward()</span></code> 方法接受任何输入,并将其转发给它的第一个模块。
然后将输出依次 “链 “到其后每个模块的输入、最后返回最后一个模块的输出。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>modules</strong> – 添加的Module</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sequential</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="c1"># 使用Sequential创建一个小模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">64</span><span class="p">,(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLu</span><span class="p">()</span>
        <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="c1"># 基于OrderedDict来使用Sequential, 代码如下</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">([</span>
          <span class="p">(</span><span class="s1">&#39;conv1&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))),</span>
          <span class="p">(</span><span class="s1">&#39;relu1&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLu</span><span class="p">()),</span>
          <span class="p">(</span><span class="s1">&#39;conv2&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">64</span><span class="p">,(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))),</span>
          <span class="p">(</span><span class="s1">&#39;relu2&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLu</span><span class="p">())</span>
        <span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="id6">
<h2>经典神经网络层<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h2>
<p>以下实现了一些经典神经网络层:卷积,转置卷积,池化,归一化,循环神经网络等。</p>
<section id="conv1d">
<h3>Conv1D<a class="headerlink" href="#conv1d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Conv1D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Conv1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Conv1D" title="Link to this definition">¶</a></dt>
<dd><p>在输入上进行一维卷积运算。 Conv1D模块的输入具有形状(batch_size、input_channels、in_height)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channels</strong> – <cite>int</cite> - 输入数据的通道数。</p></li>
<li><p><strong>output_channels</strong> – <cite>int</cite> - 输出数据的通道数。</p></li>
<li><p><strong>kernel_size</strong> – <cite>int</cite> - 卷积核的尺寸. 卷积核形状 = [output_channels,input_channels/group,kernel_size,1]。</p></li>
<li><p><strong>stride</strong> – <cite>int</cite> - 步长, 默认为1。</p></li>
<li><p><strong>padding</strong> – <cite>str|int</cite> - 填充选项, 它可以是一个字符串 {‘valid’, ‘same’} 或一个整数,给出应用在输入上的填充量。 默认 “valid”。</p></li>
<li><p><strong>use_bias</strong> – <cite>bool</cite> - 是否使用偏置项, 默认使用。</p></li>
<li><p><strong>kernel_initializer</strong> – <cite>callable</cite> - 卷积核初始化方法。默认为空,使用kaiming_uniform。</p></li>
<li><p><strong>bias_initializer</strong> – <cite>callable</cite> - 偏置初始化方法。默认为空,使用kaiming_uniform。</p></li>
<li><p><strong>dilation_rate</strong> – <cite>int</cite> - 空洞大小,defaults: 1。</p></li>
<li><p><strong>group</strong> – <cite>int</cite> -  分组卷积的分组数. Default: 1。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 模块的名字,default:””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一维卷积实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的out_height 为 = ceil(in_height / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv1D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">b</span><span class="o">=</span> <span class="mi">2</span>
<span class="n">ic</span> <span class="o">=</span><span class="mi">3</span>
<span class="n">oc</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="n">ic</span><span class="p">,</span><span class="n">oc</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">*</span><span class="n">ic</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span> <span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="mi">25</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[12.4438553, 14.8618164, 15.5595102, 16.2572021, 16.9548950, 17.6525879, 18.3502808, 19.0479736, 19.7456665, 20.4433594, 21.1410522, 21.8387432, 10.5725441],</span>
<span class="c1">#  [-13.7539215, 1.0263026, 1.2747254, 1.5231485, 1.7715728, 2.0199962, 2.2684195, 2.5168428, 2.7652662, 3.0136888, 3.2621140, 3.5105357, 14.0515862]],</span>
<span class="c1"># [[47.4924164, 41.0252953, 41.7229881, 42.4206772, 43.1183739, 43.8160667, 44.5137596, 45.2114487, 45.9091415, 46.6068344, 47.3045311, 48.0022240, 18.3216572],</span>
<span class="c1">#  [-47.2381554, 10.3421783, 10.5906038, 10.8390274, 11.0874519, 11.3358765, 11.5842953, 11.8327246, 12.0811434, 12.3295631, 12.5779924, 12.8264122, 39.4719162]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="conv2d">
<h3>Conv2D<a class="headerlink" href="#conv2d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Conv2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Conv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(1,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Conv2D" title="Link to this definition">¶</a></dt>
<dd><p>在输入上进行二维卷积运算。 Conv2D模块的输入具有形状(batch_size, input_channels, height, width)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channels</strong> – <cite>int</cite> - 输入数据的通道数。</p></li>
<li><p><strong>output_channels</strong> – <cite>int</cite> - 输出数据的通道数。</p></li>
<li><p><strong>kernel_size</strong> – <cite>tuple|list</cite> - 卷积核的尺寸. 卷积核形状 = [output_channels,input_channels/group,kernel_size,kernel_size]。</p></li>
<li><p><strong>stride</strong> – <cite>tuple|list</cite> - 步长, 默认为 (1, 1)|[1,1]。</p></li>
<li><p><strong>padding</strong> – <cite>str|tuple</cite> - 填充选项, 它可以是一个字符串 {‘valid’, ‘same’} 或一个整数元组,给出在两边应用的隐式填充量。 默认 “valid”。</p></li>
<li><p><strong>use_bias</strong> – <cite>bool</cite> - 是否使用偏置项, 默认使用。</p></li>
<li><p><strong>kernel_initializer</strong> – <cite>callable</cite> - 卷积核初始化方法。默认为空,使用kaiming_uniform。</p></li>
<li><p><strong>bias_initializer</strong> – <cite>callable</cite> - 偏置初始化方法。默认为空,使用kaiming_uniform。</p></li>
<li><p><strong>dilation_rate</strong> – <cite>int</cite> - 空洞大小,defaults: 1。</p></li>
<li><p><strong>group</strong> – <cite>int</cite> -  分组卷积的分组数. Default: 1。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 模块的名字,default:””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>二维卷积实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的height 为 = ceil(height / stride), 输出的width 为 = ceil(width / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">b</span><span class="o">=</span> <span class="mi">2</span>
<span class="n">ic</span> <span class="o">=</span><span class="mi">3</span>
<span class="n">oc</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">ic</span><span class="p">,</span><span class="n">oc</span><span class="p">,(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">*</span><span class="n">ic</span><span class="o">*</span><span class="mi">5</span><span class="o">*</span><span class="mi">5</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span><span class="n">ic</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[-0.1256833, 23.8978596, 26.7449780],</span>
<span class="c1">#  [-7.2959919, 33.4023743, 42.1283913],</span>
<span class="c1">#  [-8.7684336, 25.2698975, 40.4024887]],</span>
<span class="c1"># [[33.0653763, 40.3120155, 27.3781891],</span>
<span class="c1">#  [39.2921371, 45.8685760, 38.1885109],</span>
<span class="c1">#  [23.1873779, 12.0480318, 12.7278290]]],</span>
<span class="c1"># [[[-0.9730744, 61.3967094, 79.0511856],</span>
<span class="c1">#  [-29.3652401, 75.0349350, 112.7325439],</span>
<span class="c1">#  [-26.4682808, 59.0924797, 104.2572098]],</span>
<span class="c1"># [[66.8064194, 96.0953140, 72.9157486],</span>
<span class="c1">#  [90.9154129, 110.7232437, 91.2616043],</span>
<span class="c1">#  [56.8825951, 34.6904907, 30.1957760]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="convt2d">
<h3>ConvT2D<a class="headerlink" href="#convt2d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.ConvT2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">ConvT2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'True'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.ConvT2D" title="Link to this definition">¶</a></dt>
<dd><p>在输入上进行二维转置卷积运算。 Conv2D模块的输入具有形状(batch_size, input_channels, height, width)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channels</strong> – <cite>int</cite> - 输入数据的通道数。</p></li>
<li><p><strong>output_channels</strong> – <cite>int</cite> - 输出数据的通道数。</p></li>
<li><p><strong>kernel_size</strong> – <cite>tuple|list</cite> - 卷积核的尺寸,卷积核形状 = [input_channels,output_channels/group,kernel_size,kernel_size]。</p></li>
<li><p><strong>stride</strong> – <cite>tuple|list</cite> - 步长, 默认为 (1, 1)|[1,1]。</p></li>
<li><p><strong>padding</strong> – <cite>str|tuple</cite> - 填充选项, 它可以是一个字符串 {‘valid’, ‘same’} 或一个整数元组,给出在两边应用的隐式填充量。 默认 “valid”。</p></li>
<li><p><strong>use_bias</strong> – <cite>bool</cite> - 是否使用偏置项, 默认使用。</p></li>
<li><p><strong>kernel_initializer</strong> – <cite>callable</cite> - 卷积核初始化方法。默认为空,使用kaiming_uniform。</p></li>
<li><p><strong>bias_initializer</strong> – <cite>callable</cite> - 偏置项初始化方法。默认为空,使用kaiming_uniform。</p></li>
<li><p><strong>dilation_rate</strong> – <cite>int</cite> - 空洞大小,defaults: 1。</p></li>
<li><p><strong>out_padding</strong> – 在输出形状中每个维度的一侧添加的额外尺寸。默认值:(0,0)</p></li>
<li><p><strong>group</strong> – <cite>int</cite> -  分组卷积的分组数. Default: 1。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 模块的名字,default:””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>二维转置卷积实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的height 为 = ceil(height / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvT2D</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">ConvT2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;valid&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[-3.3675897, 4.8476148, 14.2448473, 14.8897810, 15.5347166, 20.0420666, 10.9831696],</span>
<span class="c1">#  [-14.0110836, -3.2500827, 6.4022207, 6.5149083, 6.6275964, 23.7946320, 12.1828709],</span>
<span class="c1">#  [-22.2661152, -3.5112300, 12.9493723, 13.5486069, 14.1478367, 39.6327629, 18.8349991],</span>
<span class="c1">#  [-24.4063797, -3.0093837, 15.9455290, 16.5447617, 17.1439915, 44.7691879, 21.3293095],</span>
<span class="c1">#  [-26.5466480, -2.5075383, 18.9416828, 19.5409145, 20.1401463, 49.9056053, 23.8236179],</span>
<span class="c1">#  [-24.7624626, -13.7395811, -7.9510674, -7.9967723, -8.0424776, 19.2783546, 7.0562835],</span>
<span class="c1">#  [-3.5170188, 10.2280807, 16.1939259, 16.6804695, 17.1670132, 21.2262039, 6.2889833]],</span>
<span class="c1"># [[-2.0570512, -9.5056667, -25.0429192, -25.9464111, -26.8499031, -24.7305946, -16.9881954],</span>
<span class="c1">#  [-0.7620960, -18.3383904, -49.8948288, -51.2528229, -52.6108208, -52.2179604, -34.3664169],</span>
<span class="c1">#  [-11.7121849, -27.1864738, -62.2154846, -63.6433640, -65.0712280, -52.6787071, -38.4497032],</span>
<span class="c1">#  [-13.3643141, -29.0211792, -69.3548126, -70.7826691, -72.2105408, -58.1659012, -43.7543182],</span>
<span class="c1">#  [-15.0164423, -30.8558884, -76.4941254, -77.9219971, -79.3498535, -63.6530838, -49.0589256],</span>
<span class="c1">#  [-11.6070204, -14.1940546, -35.5471687, -36.0715408, -36.5959129, -23.9147663, -22.8668022],</span>
<span class="c1">#  [-14.4390459, -4.9011412, -6.4719801, -6.5418491, -6.6117167, 9.3329525, -1.7254852]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="avgpool1d">
<h3>AvgPool1D<a class="headerlink" href="#avgpool1d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.AvgPool1D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">AvgPool1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.AvgPool1D" title="Link to this definition">¶</a></dt>
<dd><p>对一维输入进行平均池化。输入具有形状(batch_size, input_channels, in_height)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – 平均池化的窗口大小。</p></li>
<li><p><strong>strides</strong> – 窗口移动的步长。</p></li>
<li><p><strong>padding</strong> – 填充选项, “valid” or “same” 或者整数指定填充长度。 默认 “valid”。</p></li>
<li><p><strong>name</strong> – 模块的名字,default:””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一维平均池化层实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的out_height 为 = ceil(in_height / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">AvgPool1D</span>
<span class="n">test_mp</span> <span class="o">=</span> <span class="n">AvgPool1D</span><span class="p">([</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">],</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span>
                            <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">y</span><span class="o">=</span> <span class="n">test_mp</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1"># [</span>
<span class="c1"># [[0.3333333, 1.6666666, 3.],</span>
<span class="c1">#  [1.6666666, 2., 1.3333334],</span>
<span class="c1">#  [2.6666667, 2.6666667, 2.3333333],</span>
<span class="c1">#  [2.3333333, 4.3333335, 3.3333333],</span>
<span class="c1">#  [0.3333333, 1.6666666, 4.]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="maxpool1d">
<h3>MaxPool1D<a class="headerlink" href="#maxpool1d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.MaxPool1D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">MaxPool1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.MaxPool1D" title="Link to this definition">¶</a></dt>
<dd><p>对一维输入进行最大池化。输入具有形状(batch_size, input_channels, in_height)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – 最大池化的窗口大小。</p></li>
<li><p><strong>strides</strong> – 窗口移动的步长。</p></li>
<li><p><strong>padding</strong> – 填充选项, “valid” or “same” 或者整数指定填充长度。 默认 “valid”。</p></li>
<li><p><strong>name</strong> – 命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一维最大池化层实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的out_height 为 = ceil(in_height / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaxPool1D</span>
<span class="n">test_mp</span> <span class="o">=</span> <span class="n">MaxPool1D</span><span class="p">([</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">],</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span>
                            <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">y</span><span class="o">=</span> <span class="n">test_mp</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1">#[[[1. 4. 5.]</span>
<span class="c1">#   [3. 3. 3.]</span>
<span class="c1">#   [4. 4. 4.]</span>
<span class="c1">#   [5. 6. 6.]</span>
<span class="c1">#   [1. 5. 7.]]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="avgpool2d">
<h3>AvgPool2D<a class="headerlink" href="#avgpool2d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.AvgPool2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">AvgPool2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.AvgPool2D" title="Link to this definition">¶</a></dt>
<dd><p>对二维输入进行平均池化。输入具有形状(batch_size, input_channels, height, width)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – 平均池化的窗口大小。</p></li>
<li><p><strong>strides</strong> – 窗口移动的步长。</p></li>
<li><p><strong>padding</strong> – 填充选项, “valid” or “same” 或包含2个整数的元组,整数为两个维度上的填充长度。 默认 “valid”。</p></li>
<li><p><strong>name</strong> – 命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>二维平均池化层实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的height 为 = ceil(height / stride), 输出的width 为 = ceil(width / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">AvgPool2D</span>
<span class="n">test_mp</span> <span class="o">=</span> <span class="n">AvgPool2D</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span>
                            <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">y</span><span class="o">=</span> <span class="n">test_mp</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1">#[[[[1.5  1.75]</span>
<span class="c1">#    [3.75 3.  ]]]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="maxpool2d">
<h3>MaxPool2D<a class="headerlink" href="#maxpool2d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.MaxPool2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">MaxPool2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'valid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.MaxPool2D" title="Link to this definition">¶</a></dt>
<dd><p>对二维输入进行最大池化。输入具有形状(batch_size, input_channels, height, width)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – 最大池化的窗口大小。</p></li>
<li><p><strong>strides</strong> – 窗口移动的步长。</p></li>
<li><p><strong>padding</strong> – 填充选项, “valid” or “same” 或包含2个整数的元组,整数为两个维度上的填充长度。 默认 “valid”。</p></li>
<li><p><strong>name</strong> – 命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>二维最大池化层实例。</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> 不进行填充。</p>
<p><code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> 补零填充输入,输出的height 为 = ceil(height / stride), 输出的width 为 = ceil(width / stride)。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaxPool2D</span>
<span class="n">test_mp</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                            <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span>
                            <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">y</span><span class="o">=</span> <span class="n">test_mp</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1"># [[[[3. 4.]</span>
<span class="c1">#    [5. 6.]]]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="embedding">
<h3>Embedding<a class="headerlink" href="#embedding" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.embedding.Embedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.embedding.</span></span><span class="sig-name descname"><span class="pre">Embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">xavier_normal</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.embedding.Embedding" title="Link to this definition">¶</a></dt>
<dd><p>该模块通常用于存储词嵌入并使用索引检索它们。模块的输入是索引列表,输出是对应的词嵌入。
该层的输入应该是kint64。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_embeddings</strong> – <cite>int</cite> - 嵌入字典的大小。</p></li>
<li><p><strong>embedding_dim</strong> – <cite>int</cite> - 每个嵌入向量的大小</p></li>
<li><p><strong>weight_initializer</strong> – <cite>callable</cite> - 参数初始化方式,默认正态分布。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 嵌入层的命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a Embedding 实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.embedding</span><span class="w"> </span><span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">vlayer</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]),</span><span class="n">dtype</span><span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">kint64</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">vlayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[[-0.3168081, 0.0329394, -0.2934906],</span>
<span class="c1">#  [0.1057295, -0.2844988, -0.1687456]],</span>
<span class="c1"># [[-0.2382513, -0.3642318, -0.2257225],</span>
<span class="c1">#  [0.1563180, 0.1567665, 0.3038477]]],</span>
<span class="c1"># [[[-0.4131152, -0.0564500, -0.2804018],</span>
<span class="c1">#  [-0.2955172, -0.0009581, -0.1641144]],</span>
<span class="c1"># [[0.0692555, 0.1094901, 0.4099118],</span>
<span class="c1">#  [0.4348361, 0.0304361, -0.0061203]]],</span>
<span class="c1"># [[[-0.3310401, -0.1836129, 0.1098949],</span>
<span class="c1">#  [-0.1840732, 0.0332474, -0.0261806]],</span>
<span class="c1"># [[-0.1489778, 0.2519453, 0.3299376],</span>
<span class="c1">#  [-0.1942692, -0.1540277, -0.2335350]]]],</span>
<span class="c1"># [[[[-0.2620637, -0.3181309, -0.1857461],</span>
<span class="c1">#  [-0.0878164, -0.4180320, -0.1831555]],</span>
<span class="c1"># [[-0.0738970, -0.1888980, -0.3034399],</span>
<span class="c1">#  [0.1955448, -0.0409723, 0.3023460]]],</span>
<span class="c1"># [[[0.2430045, 0.0880465, 0.4309453],</span>
<span class="c1">#  [-0.1796514, -0.1432367, -0.1253638]],</span>
<span class="c1"># [[-0.5266719, 0.2386262, -0.0329155],</span>
<span class="c1">#  [0.1033449, -0.3442690, -0.0471130]]],</span>
<span class="c1"># [[[-0.5336705, -0.1939755, -0.3000667],</span>
<span class="c1">#  [0.0059001, 0.5567381, 0.1926173]],</span>
<span class="c1"># [[-0.2385869, -0.3910453, 0.2521235],</span>
<span class="c1">#  [-0.0246447, -0.0241158, -0.1402829]]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="batchnorm2d">
<h3>BatchNorm2d<a class="headerlink" href="#batchnorm2d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.BatchNorm2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">BatchNorm2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channel_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">zeros</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.BatchNorm2d" title="Link to this definition">¶</a></dt>
<dd><p>在 4D 输入(B、C、H、W)上应用批归一化。参照论文
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift</a> 。</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\gamma\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 为待训练参数。此外,默认情况下,在训练期间,该层会继续运行估计其计算的均值和方差,然后在评估期间用于归一化。平均方差均值保持默认动量 0.1。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channel_num</strong> – <cite>int</cite> - 输入通道数。</p></li>
<li><p><strong>momentum</strong> – <cite>float</cite> - 计算指数加权平均时的动量,默认为 0.1。</p></li>
<li><p><strong>epsilon</strong> – <cite>float</cite> - 数值稳定参数, 默认 1e-5。</p></li>
<li><p><strong>affine</strong> – <cite>bool</cite> - 一个布尔值,当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时,此模块具有可学习的每通道仿射参数,初始化为 1(用于权重)和 0(用于偏差)。默认值:<code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
<li><p><strong>beta_initializer</strong> – <cite>callable</cite> - beta的初始化方式,默认全零初始化。</p></li>
<li><p><strong>gamma_initializer</strong> – <cite>callable</cite> - gamma的的初始化方式,默认全一初始化。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 批归一化层命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>二维批归一化层实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchNorm2d</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">ic</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">17</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">ic</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[-1.3242440],</span>
<span class="c1">#  [-1.0834724],</span>
<span class="c1">#  [-0.8427007],</span>
<span class="c1">#  [-0.6019291]],</span>
<span class="c1"># [[-1.3242440],</span>
<span class="c1">#  [-1.0834724],</span>
<span class="c1">#  [-0.8427007],</span>
<span class="c1">#  [-0.6019291]]],</span>
<span class="c1"># [[[0.6019291],</span>
<span class="c1">#  [0.8427007],</span>
<span class="c1">#  [1.0834724],</span>
<span class="c1">#  [1.3242440]],</span>
<span class="c1"># [[0.6019291],</span>
<span class="c1">#  [0.8427007],</span>
<span class="c1">#  [1.0834724],</span>
<span class="c1">#  [1.3242440]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="batchnorm1d">
<h3>BatchNorm1d<a class="headerlink" href="#batchnorm1d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.BatchNorm1d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">BatchNorm1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channel_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">zeros</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">ones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.BatchNorm1d" title="Link to this definition">¶</a></dt>
<dd><p>在 2D 输入 (B,C) 上进行批归一化操作。 参照论文
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift</a> 。</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\gamma\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 为待训练参数。此外,默认情况下,在训练期间,该层会继续运行估计其计算的均值和方差,然后在评估期间用于归一化。平均方差均值保持默认动量 0.1。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channel_num</strong> – <cite>int</cite> - 输入通道数。</p></li>
<li><p><strong>momentum</strong> – <cite>float</cite> - 计算指数加权平均时的动量,默认为 0.1。</p></li>
<li><p><strong>epsilon</strong> – <cite>float</cite> - 数值稳定性常数,默认为 1e-5。</p></li>
<li><p><strong>affine</strong> – <cite>bool</cite> - 一个布尔值,当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时,此模块具有可学习的每通道仿射参数,初始化为 1(用于权重)和 0(用于偏差)。默认值:<code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
<li><p><strong>beta_initializer</strong> – <cite>callable</cite> - beta的初始化方式,默认全零初始化。</p></li>
<li><p><strong>gamma_initializer</strong> – <cite>callable</cite> - gamma的的初始化方式,默认全一初始化。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 批归一化层命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一维批归一化层实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchNorm1d</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">17</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [-1.3416405, -1.3416405, -1.3416405, -1.3416405],</span>
<span class="c1"># [-0.4472135, -0.4472135, -0.4472135, -0.4472135],</span>
<span class="c1"># [0.4472135, 0.4472135, 0.4472135, 0.4472135],</span>
<span class="c1"># [1.3416405, 1.3416405, 1.3416405, 1.3416405]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="layernormnd">
<h3>LayerNormNd<a class="headerlink" href="#layernormnd" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNormNd">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.layer_norm.</span></span><span class="sig-name descname"><span class="pre">LayerNormNd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">normalized_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNormNd" title="Link to this definition">¶</a></dt>
<dd><p>在任意输入的后D个维度上进行层归一化。具体方式如论文所述:
<a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a>。</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>对于像 (B,C,H,W,D) 这样的输入, <code class="docutils literal notranslate"><span class="pre">norm_shape</span></code> 可以是 [C,H,W,D],[H,W,D],[W,D] 或 [D] .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm_shape</strong> – <cite>float</cite> - 标准化形状。</p></li>
<li><p><strong>epsilon</strong> – <cite>float</cite> - 数值稳定性常数,默认为 1e-5。</p></li>
<li><p><strong>affine</strong> – <cite>bool</cite> - 一个布尔值,当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时,此模块具有可学习的每通道仿射参数,初始化为 1(用于权重)和 0(用于偏差)。默认值:<code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 LayerNormNd 类</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span><span class="p">,</span><span class="n">kfloat32</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.layer_norm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LayerNormNd</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">LayerNormNd</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">17</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1"># [</span>
<span class="c1"># [[[-1.3416355, -0.4472118],</span>
<span class="c1">#  [0.4472118, 1.3416355]],</span>
<span class="c1"># [[-1.3416355, -0.4472118],</span>
<span class="c1">#  [0.4472118, 1.3416355]]],</span>
<span class="c1"># [[[-1.3416355, -0.4472118],</span>
<span class="c1">#  [0.4472118, 1.3416355]],</span>
<span class="c1"># [[-1.3416355, -0.4472118],</span>
<span class="c1">#  [0.4472118, 1.3416355]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="layernorm2d">
<h3>LayerNorm2d<a class="headerlink" href="#layernorm2d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNorm2d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.layer_norm.</span></span><span class="sig-name descname"><span class="pre">LayerNorm2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">norm_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNorm2d" title="Link to this definition">¶</a></dt>
<dd><p>在 4D 输入上进行层归一化。具体方式如论文所述:
<a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a>。</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>平均值和标准差是在除去第一个维度以外的剩余维度数据上计算的。对于像 (B,C,H,W) 这样的输入, <code class="docutils literal notranslate"><span class="pre">norm_size</span></code> 应该等于 C * H * W。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm_size</strong> – <cite>float</cite> - 归一化大小,应该等于 C * H * W。</p></li>
<li><p><strong>epsilon</strong> – <cite>float</cite> - 数值稳定性常数,默认为 1e-5。</p></li>
<li><p><strong>affine</strong> – <cite>bool</cite> - 一个布尔值,当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时,此模块具有可学习的每通道仿射参数,初始化为 1(用于权重)和 0(用于偏差)。默认值:<code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>二维层归一化实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.layer_norm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LayerNorm2d</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">LayerNorm2d</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">17</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[-1.5275238],</span>
<span class="c1">#  [-1.0910884],</span>
<span class="c1">#  [-0.6546531],</span>
<span class="c1">#  [-0.2182177]],</span>
<span class="c1"># [[0.2182177],</span>
<span class="c1">#  [0.6546531],</span>
<span class="c1">#  [1.0910884],</span>
<span class="c1">#  [1.5275238]]],</span>
<span class="c1"># [[[-1.5275238],</span>
<span class="c1">#  [-1.0910884],</span>
<span class="c1">#  [-0.6546531],</span>
<span class="c1">#  [-0.2182177]],</span>
<span class="c1"># [[0.2182177],</span>
<span class="c1">#  [0.6546531],</span>
<span class="c1">#  [1.0910884],</span>
<span class="c1">#  [1.5275238]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="layernorm1d">
<h3>LayerNorm1d<a class="headerlink" href="#layernorm1d" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNorm1d">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.layer_norm.</span></span><span class="sig-name descname"><span class="pre">LayerNorm1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">norm_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.layer_norm.LayerNorm1d" title="Link to this definition">¶</a></dt>
<dd><p>在 2D 输入上进行层归一化。具体方式如论文所述:
<a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a>。</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>均值和标准差是在最后一个维度大小上计算的,其中“norm_size” 是 <code class="docutils literal notranslate"><span class="pre">norm_size</span></code> 的值。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>norm_size</strong> – <cite>float</cite> - 归一化大小,应该等于最后一维大小。</p></li>
<li><p><strong>epsilon</strong> – <cite>float</cite> - 数值稳定性常数,默认为 1e-5。</p></li>
<li><p><strong>affine</strong> – <cite>bool</cite> - 一个布尔值,当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时,此模块具有可学习的每通道仿射参数,初始化为 1(用于权重)和 0(用于偏差)。默认值:<code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一维层归一化实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.layer_norm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LayerNorm1d</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">LayerNorm1d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">17</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [-1.3416355, -0.4472118, 0.4472118, 1.3416355],</span>
<span class="c1"># [-1.3416355, -0.4472118, 0.4472118, 1.3416355],</span>
<span class="c1"># [-1.3416355, -0.4472118, 0.4472118, 1.3416355],</span>
<span class="c1"># [-1.3416355, -0.4472118, 0.4472118, 1.3416355]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="groupnorm">
<h3>GroupNorm<a class="headerlink" href="#groupnorm" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.group_norm.GroupNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.group_norm.</span></span><span class="sig-name descname"><span class="pre">GroupNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.group_norm.GroupNorm" title="Link to this definition">¶</a></dt>
<dd><p>对小批量输入应用组归一化。输入: <span class="math notranslate nohighlight">\((N, C, *)\)</span> 其中 <span class="math notranslate nohighlight">\(C=\text{num_channels}\)</span> , 输出: <span class="math notranslate nohighlight">\((N, C, *)\)</span> 。</p>
<p>此层实现论文 <a class="reference external" href="https://arxiv.org/abs/1803.08494">组归一化</a> 中描述的操作。</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>输入通道被分成 <code class="xref py py-attr docutils literal notranslate"><span class="pre">num_groups</span></code> 组,每组包含 <code class="docutils literal notranslate"><span class="pre">num_channels</span> <span class="pre">/</span> <span class="pre">num_groups</span></code> 个通道。<code class="xref py py-attr docutils literal notranslate"><span class="pre">num_channels</span></code> 必须能被 <code class="xref py py-attr docutils literal notranslate"><span class="pre">num_groups</span></code> 整除。平均值和标准差是在每个组中分别计算的。如果 <code class="xref py py-attr docutils literal notranslate"><span class="pre">affine</span></code> 为 <code class="docutils literal notranslate"><span class="pre">True</span></code>,则 <span class="math notranslate nohighlight">\(\gamma\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 是可学习的。每个通道仿射变换参数向量,大小为 <code class="xref py py-attr docutils literal notranslate"><span class="pre">num_channels</span></code>。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>(</strong><strong>int</strong><strong>)</strong> (<em>num_channels</em>) – 将通道分成的组数</p></li>
<li><p><strong>(</strong><strong>int</strong><strong>)</strong> – 输入中预期的通道数</p></li>
<li><p><strong>eps</strong> – 添加到分母的值,以实现数值稳定性。默认值:1e-5</p></li>
<li><p><strong>affine</strong> – 一个布尔值,当设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时,此模块具有可学习的每通道仿射参数,初始化为 1(用于权重)和 0(用于偏差)。默认值: <code class="docutils literal notranslate"><span class="pre">True</span></code>。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GroupNorm 类</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span><span class="p">,</span><span class="n">kfloat32</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">GroupNorm</span>
<span class="n">test_conv</span> <span class="o">=</span> <span class="n">GroupNorm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">60</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">test_conv</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="linear">
<h3>Linear<a class="headerlink" href="#linear" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Linear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Linear" title="Link to this definition">¶</a></dt>
<dd><p>线性模块(全连接层)。
<span class="math notranslate nohighlight">\(y = Ax + b\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channels</strong> – <cite>int</cite> - 输入数据通道数。</p></li>
<li><p><strong>output_channels</strong> – <cite>int</cite> - 输出数据通道数。</p></li>
<li><p><strong>weight_initializer</strong> – <cite>callable</cite> - 权重初始化函数,默认为空,使用he_uniform。</p></li>
<li><p><strong>bias_initializer</strong> – <cite>callable</cite> - 偏置初始化参数,默认为空,使用he_uniform。</p></li>
<li><p><strong>use_bias</strong> – <cite>bool</cite> - 是否使用偏置项, 默认使用。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 线性层的命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>线性层实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Linear</span>
<span class="n">c1</span> <span class="o">=</span><span class="mi">2</span>
<span class="n">c2</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">cin</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">cout</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span><span class="n">cout</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">c1</span><span class="o">*</span><span class="n">c2</span><span class="o">*</span><span class="n">cin</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">c1</span><span class="p">,</span><span class="n">c2</span><span class="p">,</span><span class="n">cin</span><span class="p">)),</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[4.3084583, -1.9228780, -0.3428757, 1.2840536, -0.5865945],</span>
<span class="c1">#  [9.8339605, -5.5135884, -3.1228657, 4.3025794, -4.1492314],</span>
<span class="c1">#  [15.3594627, -9.1042995, -5.9028554, 7.3211040, -7.7118683]],</span>
<span class="c1"># [[20.8849659, -12.6950111, -8.6828451, 10.3396301, -11.2745066],</span>
<span class="c1">#  [26.4104652, -16.2857227, -11.4628344, 13.3581581, -14.8371439],</span>
<span class="c1">#  [31.9359703, -19.8764324, -14.2428246, 16.3766804, -18.3997803]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="dropout">
<h3>Dropout<a class="headerlink" href="#dropout" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.dropout.Dropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.dropout.</span></span><span class="sig-name descname"><span class="pre">Dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.dropout.Dropout" title="Link to this definition">¶</a></dt>
<dd><p>Dropout 模块。dropout 模块将一些单元的输出随机设置为零,同时根据给定的 dropout_rate 概率升级其他单元。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dropout_rate</strong> – <cite>float</cite> - 神经元被设置为零的概率。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dropout实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn.dropout</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dropout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ic</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">ic</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">ic</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">ic</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">droplayer</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">droplayer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">droplayer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[-16., -14.],</span>
<span class="c1">#  [-0., -0.]],</span>
<span class="c1"># [[-8., -6.],</span>
<span class="c1">#  [-4., -2.]]],</span>
<span class="c1"># [[[0., 2.],</span>
<span class="c1">#  [4., 6.]],</span>
<span class="c1"># [[8., 10.],</span>
<span class="c1">#  [0., 14.]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="droppath">
<h3>DropPath<a class="headerlink" href="#droppath" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.dropout.DropPath">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.dropout.</span></span><span class="sig-name descname"><span class="pre">DropPath</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.dropout.DropPath" title="Link to this definition">¶</a></dt>
<dd><p>DropPath 模块将逐样本丢弃路径(随机深度)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dropout_rate</strong> – <cite>float</cite> - 神经元被设置为零的概率。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>DropPath实例。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">randu</span><span class="p">([</span><span class="mi">4</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DropPath</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1">#[0.9074978,0.9350062,0.6896403,0.3541051]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="pixel-shuffle">
<h3>Pixel_Shuffle<a class="headerlink" href="#pixel-shuffle" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.pixel_shuffle.Pixel_Shuffle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.pixel_shuffle.</span></span><span class="sig-name descname"><span class="pre">Pixel_Shuffle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">upscale_factors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.pixel_shuffle.Pixel_Shuffle" title="Link to this definition">¶</a></dt>
<dd><p>重新排列形状为:(<em>, C * r^2, H, W)  的张量
到形状为 (</em>, C, H * r, W * r) 的张量,其中 r 是尺度变换因子。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>upscale_factors</strong> – 增加尺度变换的因子</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pixel_Shuffle 模块</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pixel_Shuffle</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">Pixel_Shuffle</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">inx</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">inx</span><span class="o">.</span><span class="n">requires_grad</span><span class="o">=</span>  <span class="kc">True</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ps</span><span class="p">(</span><span class="n">inx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#[5, 2, 3, 2, 12, 12]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="pixel-unshuffle">
<h3>Pixel_Unshuffle<a class="headerlink" href="#pixel-unshuffle" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.pixel_shuffle.Pixel_Unshuffle">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.pixel_shuffle.</span></span><span class="sig-name descname"><span class="pre">Pixel_Unshuffle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">downscale_factors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.pixel_shuffle.Pixel_Unshuffle" title="Link to this definition">¶</a></dt>
<dd><p>通过重新排列元素来反转 Pixel_Shuffle 操作. 将 (<em>, C, H * r, W * r) 形状的张量变化为 (</em>, C * r^2, H, W) ,其中 r 是缩小因子。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>downscale_factors</strong> – 增加尺度变换的因子</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pixel_Unshuffle 模块</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pixel_Unshuffle</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">Pixel_Unshuffle</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">inx</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">inx</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ps</span><span class="p">(</span><span class="n">inx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1">#[5, 2, 3, 18, 4, 4]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="gru">
<h3>GRU<a class="headerlink" href="#gru" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.gru.GRU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.gru.</span></span><span class="sig-name descname"><span class="pre">GRU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinearity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.gru.GRU" title="Link to this definition">¶</a></dt>
<dd><p>门控循环单元 (GRU) 模块。支持多层堆叠,双向配置。单层单向GRU的计算公式如下:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
    r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
    z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\
    n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
    h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 输入特征维度。</p></li>
<li><p><strong>hidden_size</strong> – 隐藏特征维度。</p></li>
<li><p><strong>num_layers</strong> – 堆叠GRU层数, 默认: 1。</p></li>
<li><p><strong>batch_first</strong> – 如果为 True, 则输入形状为 [batch_size,seq_len,feature_dim],
如果为 False, 则输入形状为 [seq_len,batch_size,feature_dim],默认为 True。</p></li>
<li><p><strong>use_bias</strong> – 如果为 False,该模块不适用偏置项,默认: True。</p></li>
<li><p><strong>bidirectional</strong> – 如果为 True, 变为双向GRU, 默认: False。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>GRU 实例</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">GRU</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>

<span class="n">rnn2</span> <span class="o">=</span> <span class="n">GRU</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span>
<span class="c1"># [</span>
<span class="c1"># [[0.2815045, 0.2056844, 0.0750246, 0.5802019, 0.3536537, 0.8136684, -0.0034523, 0.1634004, 0.6099871, 0.8451654, -0.2833570, 0.7294812],</span>
<span class="c1">#  [0.2815045, 0.2056844, 0.0750246, 0.5802019, 0.3536537, 0.8136684, -0.0034523, 0.1634004, 0.6099871, 0.8451654, -0.2833570, 0.7294812],</span>
<span class="c1">#  [0.2815045, 0.2056844, 0.0750246, 0.5802019, 0.3536537, 0.8136684, -0.0034523, 0.1634004, 0.6099871, 0.8451654, -0.2833570, 0.7294812]],</span>
<span class="c1"># [[0.0490867, 0.0115325, -0.2797680, 0.4711050, -0.0687061, 0.7216146, 0.0258964, 0.0619203, 0.6341010, 0.8445141, -0.4164453, 0.7409840],</span>
<span class="c1">#  [0.0490867, 0.0115325, -0.2797680, 0.4711050, -0.0687061, 0.7216146, 0.0258964, 0.0619203, 0.6341010, 0.8445141, -0.4164453, 0.7409840],</span>
<span class="c1">#  [0.0490867, 0.0115325, -0.2797680, 0.4711050, -0.0687061, 0.7216146, 0.0258964, 0.0619203, 0.6341010, 0.8445141, -0.4164453, 0.7409840]],</span>
<span class="c1"># [[0.0182974, -0.0536071, -0.4478674, 0.4315647, -0.2191887, 0.6492687, 0.1572548, 0.0839213, 0.6707115, 0.8444533, -0.3811499, 0.7448123],</span>
<span class="c1">#  [0.0182974, -0.0536071, -0.4478674, 0.4315647, -0.2191887, 0.6492687, 0.1572548, 0.0839213, 0.6707115, 0.8444533, -0.3811499, 0.7448123],</span>
<span class="c1">#  [0.0182974, -0.0536071, -0.4478674, 0.4315647, -0.2191887, 0.6492687, 0.1572548, 0.0839213, 0.6707115, 0.8444533, -0.3811499, 0.7448123]],</span>
<span class="c1"># [[0.0722285, -0.0636698, -0.5457084, 0.3817562, -0.1890205, 0.5696942, 0.3855782, 0.2057217, 0.7370453, 0.8646453, -0.1967214, 0.7630759],</span>
<span class="c1">#  [0.0722285, -0.0636698, -0.5457084, 0.3817562, -0.1890205, 0.5696942, 0.3855782, 0.2057217, 0.7370453, 0.8646453, -0.1967214, 0.7630759],</span>
<span class="c1">#  [0.0722285, -0.0636698, -0.5457084, 0.3817562, -0.1890205, 0.5696942, 0.3855782, 0.2057217, 0.7370453, 0.8646453, -0.1967214, 0.7630759]],</span>
<span class="c1"># [[0.1834545, -0.0489200, -0.6343678, 0.3061281, -0.0449328, 0.4901535, 0.6941375, 0.4570828, 0.8433002, 0.9152645, 0.2342478, 0.8299093],</span>
<span class="c1">#  [0.1834545, -0.0489200, -0.6343678, 0.3061281, -0.0449328, 0.4901535, 0.6941375, 0.4570828, 0.8433002, 0.9152645, 0.2342478, 0.8299093],</span>
<span class="c1">#  [0.1834545, -0.0489200, -0.6343678, 0.3061281, -0.0449328, 0.4901535, 0.6941375, 0.4570828, 0.8433002, 0.9152645, 0.2342478, 0.8299093]]</span>
<span class="c1"># ]</span>
<span class="c1"># [</span>
<span class="c1"># [[-0.8070476, -0.5560303, 0.7575479, -0.2368367, 0.4228620, -0.2573725],</span>
<span class="c1">#  [-0.8070476, -0.5560303, 0.7575479, -0.2368367, 0.4228620, -0.2573725],</span>
<span class="c1">#  [-0.8070476, -0.5560303, 0.7575479, -0.2368367, 0.4228620, -0.2573725]],</span>
<span class="c1"># [[-0.3857390, -0.3195596, 0.0281313, 0.8734715, -0.4499536, 0.2270730],</span>
<span class="c1">#  [-0.3857390, -0.3195596, 0.0281313, 0.8734715, -0.4499536, 0.2270730],</span>
<span class="c1">#  [-0.3857390, -0.3195596, 0.0281313, 0.8734715, -0.4499536, 0.2270730]],</span>
<span class="c1"># [[0.1834545, -0.0489200, -0.6343678, 0.3061281, -0.0449328, 0.4901535],</span>
<span class="c1">#  [0.1834545, -0.0489200, -0.6343678, 0.3061281, -0.0449328, 0.4901535],</span>
<span class="c1">#  [0.1834545, -0.0489200, -0.6343678, 0.3061281, -0.0449328, 0.4901535]],</span>
<span class="c1"># [[-0.0034523, 0.1634004, 0.6099871, 0.8451654, -0.2833570, 0.7294812],</span>
<span class="c1">#  [-0.0034523, 0.1634004, 0.6099871, 0.8451654, -0.2833570, 0.7294812],</span>
<span class="c1">#  [-0.0034523, 0.1634004, 0.6099871, 0.8451654, -0.2833570, 0.7294812]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="rnn">
<h3>RNN<a class="headerlink" href="#rnn" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.rnn.RNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.rnn.</span></span><span class="sig-name descname"><span class="pre">RNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinearity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.rnn.RNN" title="Link to this definition">¶</a></dt>
<dd><p>循环神经网络(RNN)模块,使用 <span class="math notranslate nohighlight">\(\tanh\)</span> 或 <span class="math notranslate nohighlight">\(\text{ReLU}\)</span> 作为激活函数。支持双向,多层配置。
单层单向RNN计算公式如下:</p>
<div class="math notranslate nohighlight">
\[h_t = \tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\]</div>
<p>如果 <code class="xref py py-attr docutils literal notranslate"><span class="pre">nonlinearity</span></code> 是 <code class="docutils literal notranslate"><span class="pre">'relu'</span></code>, 则 <span class="math notranslate nohighlight">\(\text{ReLU}\)</span> 将替代 <span class="math notranslate nohighlight">\(\tanh\)</span>。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 输入特征维度。</p></li>
<li><p><strong>hidden_size</strong> – 隐藏特征维度。</p></li>
<li><p><strong>num_layers</strong> – 堆叠RNN层数, 默认: 1。</p></li>
<li><p><strong>nonlinearity</strong> – 非线性激活函数,默认为 <code class="docutils literal notranslate"><span class="pre">'tanh'</span></code>。</p></li>
<li><p><strong>batch_first</strong> – 如果为 True, 则输入形状为 [batch_size,seq_len,feature_dim],
如果为 False, 则输入形状为 [seq_len,batch_size,feature_dim],默认为 True。</p></li>
<li><p><strong>use_bias</strong> – 如果为 False, 该模块不适用偏置项,默认: True。</p></li>
<li><p><strong>bidirectional</strong> – 如果为 True,变为双向RNN,默认: False。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>RNN 实例</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">RNN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>

<span class="n">rnn2</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bidirectional</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span>

<span class="c1"># [[[-0.413501  -0.4584284 -0.7530673  0.017902   0.5038776  0.6589128</span>
<span class="c1">#    -0.3040171  0.6689512 -0.5059364 -0.4492912 -0.1206206 -0.3208488]</span>
<span class="c1">#   [-0.413501  -0.4584284 -0.7530673  0.017902   0.5038776  0.6589128</span>
<span class="c1">#    -0.3040171  0.6689512 -0.5059364 -0.4492912 -0.1206206 -0.3208488]</span>
<span class="c1">#   [-0.413501  -0.4584284 -0.7530673  0.017902   0.5038776  0.6589128</span>
<span class="c1">#    -0.3040171  0.6689512 -0.5059364 -0.4492912 -0.1206206 -0.3208488]]</span>

<span class="c1">#  [[ 0.2127696 -0.6644132 -0.3884572 -0.0344413  0.35414    0.5639224</span>
<span class="c1">#    -0.2358238  0.7706838 -0.3650029 -0.54729   -0.2392456 -0.3285939]</span>
<span class="c1">#   [ 0.2127696 -0.6644132 -0.3884572 -0.0344413  0.35414    0.5639224</span>
<span class="c1">#    -0.2358238  0.7706838 -0.3650029 -0.54729   -0.2392456 -0.3285939]</span>
<span class="c1">#   [ 0.2127696 -0.6644132 -0.3884572 -0.0344413  0.35414    0.5639224</span>
<span class="c1">#    -0.2358238  0.7706838 -0.3650029 -0.54729   -0.2392456 -0.3285939]]</span>

<span class="c1">#  [[ 0.0432173 -0.3811357 -0.4611054 -0.255436   0.4998702  0.6649145</span>
<span class="c1">#    -0.3132874  0.5965794 -0.5760088 -0.5618317 -0.2404964 -0.4669401]</span>
<span class="c1">#   [ 0.0432173 -0.3811357 -0.4611054 -0.255436   0.4998702  0.6649145</span>
<span class="c1">#    -0.3132874  0.5965794 -0.5760088 -0.5618317 -0.2404964 -0.4669401]</span>
<span class="c1">#   [ 0.0432173 -0.3811357 -0.4611054 -0.255436   0.4998702  0.6649145</span>
<span class="c1">#    -0.3132874  0.5965794 -0.5760088 -0.5618317 -0.2404964 -0.4669401]]</span>

<span class="c1">#  [[ 0.1083845 -0.4397578 -0.4745184 -0.2148822  0.3674186  0.6907974</span>
<span class="c1">#    -0.061549   0.452508  -0.5262724 -0.3184315 -0.4691838 -0.0438465]</span>
<span class="c1">#   [ 0.1083845 -0.4397578 -0.4745184 -0.2148822  0.3674186  0.6907974</span>
<span class="c1">#    -0.061549   0.452508  -0.5262724 -0.3184315 -0.4691838 -0.0438465]</span>
<span class="c1">#   [ 0.1083845 -0.4397578 -0.4745184 -0.2148822  0.3674186  0.6907974</span>
<span class="c1">#    -0.061549   0.452508  -0.5262724 -0.3184315 -0.4691838 -0.0438465]]</span>

<span class="c1">#  [[-0.1835401 -0.6232781 -0.3571274  0.2283377  0.5426646  0.6719067</span>
<span class="c1">#    -0.8672301  0.0971878 -0.7561615 -0.5063094  0.5117968 -0.0985391]</span>
<span class="c1">#   [-0.1835401 -0.6232781 -0.3571274  0.2283377  0.5426646  0.6719067</span>
<span class="c1">#    -0.8672301  0.0971878 -0.7561615 -0.5063094  0.5117968 -0.0985391]</span>
<span class="c1">#   [-0.1835401 -0.6232781 -0.3571274  0.2283377  0.5426646  0.6719067</span>
<span class="c1">#    -0.8672301  0.0971878 -0.7561615 -0.5063094  0.5117968 -0.0985391]]]</span>
<span class="c1"># [[[ 0.2451548  0.9127097 -0.6998036  0.6434992  0.1046313  0.6530996]</span>
<span class="c1">#   [ 0.2451548  0.9127097 -0.6998036  0.6434992  0.1046313  0.6530996]</span>
<span class="c1">#   [ 0.2451548  0.9127097 -0.6998036  0.6434992  0.1046313  0.6530996]]</span>

<span class="c1">#  [[-0.1760802 -0.546555   0.7547818  0.8418489 -0.2011115  0.1687339]</span>
<span class="c1">#   [-0.1760802 -0.546555   0.7547818  0.8418489 -0.2011115  0.1687339]</span>
<span class="c1">#   [-0.1760802 -0.546555   0.7547818  0.8418489 -0.2011115  0.1687339]]</span>

<span class="c1">#  [[-0.1835401 -0.6232781 -0.3571274  0.2283377  0.5426646  0.6719067]</span>
<span class="c1">#   [-0.1835401 -0.6232781 -0.3571274  0.2283377  0.5426646  0.6719067]</span>
<span class="c1">#   [-0.1835401 -0.6232781 -0.3571274  0.2283377  0.5426646  0.6719067]]</span>

<span class="c1">#  [[-0.3040171  0.6689512 -0.5059364 -0.4492912 -0.1206206 -0.3208488]</span>
<span class="c1">#   [-0.3040171  0.6689512 -0.5059364 -0.4492912 -0.1206206 -0.3208488]</span>
<span class="c1">#   [-0.3040171  0.6689512 -0.5059364 -0.4492912 -0.1206206 -0.3208488]]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="lstm">
<h3>LSTM<a class="headerlink" href="#lstm" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.lstm.LSTM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.lstm.</span></span><span class="sig-name descname"><span class="pre">LSTM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.lstm.LSTM" title="Link to this definition">¶</a></dt>
<dd><p>长短期记忆(LSTM)模块。支持双向LSTM, 堆叠多层LSTM等配置。单层单向LSTM计算公式如下:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\
    f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\
    g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\
    o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\
    c_t = f_t \odot c_{t-1} + i_t \odot g_t \\
    h_t = o_t \odot \tanh(c_t) \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 输入特征维度。</p></li>
<li><p><strong>hidden_size</strong> – 隐藏特征维度。</p></li>
<li><p><strong>num_layers</strong> – 堆叠LSTM层数,默认: 1。</p></li>
<li><p><strong>batch_first</strong> – 如果为 True,则输入形状为 [batch_size,seq_len,feature_dim],
如果为 False, 则输入形状为 [seq_len,batch_size,feature_dim],默认为 True。</p></li>
<li><p><strong>use_bias</strong> – 如果为 False,该模块不适用偏置项, 默认: True。</p></li>
<li><p><strong>bidirectional</strong> – 如果为 True,变为双向LSTM, 默认: False。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>LSTM 实例</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>

<span class="n">rnn2</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bidirectional</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">c0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">rnn2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cn</span><span class="p">)</span>

<span class="c1"># [[[ 0.2732482  0.1701475  0.1449948  0.0736707  0.1340735  0.1299259</span>
<span class="c1">#     0.0551452  0.2563322  0.040974   0.1358014 -0.1953781 -0.061493 ]</span>
<span class="c1">#   [ 0.2732482  0.1701475  0.1449948  0.0736707  0.1340735  0.1299259</span>
<span class="c1">#     0.0551452  0.2563322  0.040974   0.1358014 -0.1953781 -0.061493 ]</span>
<span class="c1">#   [ 0.2732482  0.1701475  0.1449948  0.0736707  0.1340735  0.1299259</span>
<span class="c1">#     0.0551452  0.2563322  0.040974   0.1358014 -0.1953781 -0.061493 ]]</span>

<span class="c1">#  [[ 0.0973835  0.2728153  0.0826659  0.1486651  0.001023  -0.0002572</span>
<span class="c1">#     0.0662036  0.2953667  0.0374205  0.1520839 -0.1803852 -0.0302957]</span>
<span class="c1">#   [ 0.0973835  0.2728153  0.0826659  0.1486651  0.001023  -0.0002572</span>
<span class="c1">#     0.0662036  0.2953667  0.0374205  0.1520839 -0.1803852 -0.0302957]</span>
<span class="c1">#   [ 0.0973835  0.2728153  0.0826659  0.1486651  0.001023  -0.0002572</span>
<span class="c1">#     0.0662036  0.2953667  0.0374205  0.1520839 -0.1803852 -0.0302957]]</span>

<span class="c1">#  [[ 0.0228571  0.1898227  0.0312898  0.1559544 -0.0909701 -0.0543313</span>
<span class="c1">#     0.0921322  0.3542943  0.0323457  0.1877485 -0.1509136  0.0398105]</span>
<span class="c1">#   [ 0.0228571  0.1898227  0.0312898  0.1559544 -0.0909701 -0.0543313</span>
<span class="c1">#     0.0921322  0.3542943  0.0323457  0.1877485 -0.1509136  0.0398105]</span>
<span class="c1">#   [ 0.0228571  0.1898227  0.0312898  0.1559544 -0.0909701 -0.0543313</span>
<span class="c1">#     0.0921322  0.3542943  0.0323457  0.1877485 -0.1509136  0.0398105]]</span>

<span class="c1">#  [[-0.0164866  0.1411722 -0.002618   0.1457977 -0.1280925 -0.0702658</span>
<span class="c1">#     0.1419625  0.4266106  0.0363048  0.2426503 -0.0849762  0.1489675]</span>
<span class="c1">#   [-0.0164866  0.1411722 -0.002618   0.1457977 -0.1280925 -0.0702658</span>
<span class="c1">#     0.1419625  0.4266106  0.0363048  0.2426503 -0.0849762  0.1489675]</span>
<span class="c1">#   [-0.0164866  0.1411722 -0.002618   0.1457977 -0.1280925 -0.0702658</span>
<span class="c1">#     0.1419625  0.4266106  0.0363048  0.2426503 -0.0849762  0.1489675]]</span>

<span class="c1">#  [[-0.0223669  0.1591602 -0.0311901  0.0958475 -0.122227  -0.0682742</span>
<span class="c1">#     0.2645994  0.4319879  0.0528811  0.3815826  0.1058483  0.1233259]</span>
<span class="c1">#   [-0.0223669  0.1591602 -0.0311901  0.0958475 -0.122227  -0.0682742</span>
<span class="c1">#     0.2645994  0.4319879  0.0528811  0.3815826  0.1058483  0.1233259]</span>
<span class="c1">#   [-0.0223669  0.1591602 -0.0311901  0.0958475 -0.122227  -0.0682742</span>
<span class="c1">#     0.2645994  0.4319879  0.0528811  0.3815826  0.1058483  0.1233259]]]</span>
<span class="c1"># [[[ 0.1752738 -0.0356635  0.2989266  0.20517   -0.0896036  0.5098922]</span>
<span class="c1">#   [ 0.1752738 -0.0356635  0.2989266  0.20517   -0.0896036  0.5098922]</span>
<span class="c1">#   [ 0.1752738 -0.0356635  0.2989266  0.20517   -0.0896036  0.5098922]]</span>

<span class="c1">#  [[-0.2443907 -0.0827548 -0.1557958  0.1731217 -0.0342197 -0.1101249]</span>
<span class="c1">#   [-0.2443907 -0.0827548 -0.1557958  0.1731217 -0.0342197 -0.1101249]</span>
<span class="c1">#   [-0.2443907 -0.0827548 -0.1557958  0.1731217 -0.0342197 -0.1101249]]</span>

<span class="c1">#  [[-0.0223669  0.1591602 -0.0311901  0.0958475 -0.122227  -0.0682742]</span>
<span class="c1">#   [-0.0223669  0.1591602 -0.0311901  0.0958475 -0.122227  -0.0682742]</span>
<span class="c1">#   [-0.0223669  0.1591602 -0.0311901  0.0958475 -0.122227  -0.0682742]]</span>

<span class="c1">#  [[ 0.0551452  0.2563322  0.040974   0.1358014 -0.1953781 -0.061493 ]</span>
<span class="c1">#   [ 0.0551452  0.2563322  0.040974   0.1358014 -0.1953781 -0.061493 ]</span>
<span class="c1">#   [ 0.0551452  0.2563322  0.040974   0.1358014 -0.1953781 -0.061493 ]]]</span>
<span class="c1"># [[[ 0.3543518 -0.1842273  0.8745036  0.6013567 -0.1227313  1.0065726]</span>
<span class="c1">#   [ 0.3543518 -0.1842273  0.8745036  0.6013567 -0.1227313  1.0065726]</span>
<span class="c1">#   [ 0.3543518 -0.1842273  0.8745036  0.6013567 -0.1227313  1.0065726]]</span>

<span class="c1">#  [[-0.5912023 -0.2058601 -0.4632604  0.3671726 -0.0673411 -0.327456 ]</span>
<span class="c1">#   [-0.5912023 -0.2058601 -0.4632604  0.3671726 -0.0673411 -0.327456 ]</span>
<span class="c1">#   [-0.5912023 -0.2058601 -0.4632604  0.3671726 -0.0673411 -0.327456 ]]</span>

<span class="c1">#  [[-0.0393696  0.301177  -0.0757513  0.196299  -0.3163165 -0.1804099]</span>
<span class="c1">#   [-0.0393696  0.301177  -0.0757513  0.196299  -0.3163165 -0.1804099]</span>
<span class="c1">#   [-0.0393696  0.301177  -0.0757513  0.196299  -0.3163165 -0.1804099]]</span>

<span class="c1">#  [[ 0.1547394  0.4916601  0.1061193  0.2582704 -0.3499697 -0.1048216]</span>
<span class="c1">#   [ 0.1547394  0.4916601  0.1061193  0.2582704 -0.3499697 -0.1048216]</span>
<span class="c1">#   [ 0.1547394  0.4916601  0.1061193  0.2582704 -0.3499697 -0.1048216]]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="dynamic-gru">
<h3>Dynamic_GRU<a class="headerlink" href="#dynamic-gru" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.gru.Dynamic_GRU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.gru.</span></span><span class="sig-name descname"><span class="pre">Dynamic_GRU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.gru.Dynamic_GRU" title="Link to this definition">¶</a></dt>
<dd><p>将多层门控循环单元 (GRU) RNN 应用于动态长度输入序列。</p>
<p>第一个输入应该是定义了可变长度的批处理序列输入
通过 <code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类。
<code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类可以构造为
连续调用下一个函数: <code class="docutils literal notranslate"><span class="pre">pad_sequence</span></code> 、 <code class="docutils literal notranslate"><span class="pre">pack_pad_sequence</span></code>。</p>
<p>Dynamic_GRU 的第一个输出也是一个 <code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类,
可以使用 <code class="docutils literal notranslate"><span class="pre">tensor.pad_pack_sequence</span></code> 将其解压缩为普通 QTensor。</p>
<p>对于输入序列中的每个元素,每一层计算以下公式:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
    r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
    z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\
    n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
    h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 输入特征维度。</p></li>
<li><p><strong>hidden_size</strong> – 隐藏的特征维度。</p></li>
<li><p><strong>num_layers</strong> – 循环层数。 默认值:1</p></li>
<li><p><strong>batch_first</strong> – 如果为 True,输入形状提供为 [批大小,序列长度,特征维度]。如果为 False,输入形状提供为 [序列长度,批大小,特征维度],默认为 True。</p></li>
<li><p><strong>use_bias</strong> – 如果为False,则该层不使用偏置权重b_ih和b_hh。 默认值:True。</p></li>
<li><p><strong>bidirectional</strong> – 如果为真,则成为双向 GRU。 默认值:False。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 Dynamic_GRU 类</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dynamic_GRU</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">batch_size</span> <span class="o">=</span><span class="mi">3</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ml</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">rnn2</span> <span class="o">=</span> <span class="n">Dynamic_GRU</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
                <span class="n">hidden_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="kc">False</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">pack_pad_sequence</span><span class="p">(</span><span class="n">y</span><span class="p">,</span>
                                <span class="n">seq_len</span><span class="p">,</span>
                                <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">h0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">ml</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">])</span>

<span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="n">seq_unpacked</span><span class="p">,</span> <span class="n">lens_unpacked</span> <span class="o">=</span> \
<span class="n">tensor</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">seq_unpacked</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lens_unpacked</span><span class="p">)</span>
<span class="c1"># [</span>
<span class="c1"># [[-0.3918380, 0.0056273, 0.9018179, 0.9006662],</span>
<span class="c1">#  [-0.3715909, 0.0307644, 0.9756137, 0.9705784],</span>
<span class="c1">#  [-0.3917399, 0.0057521, 0.9507942, 0.9456232]],</span>
<span class="c1"># [[-0.6348240, -0.0603764, 0.9014163, 0.8903066],</span>
<span class="c1">#  [0., 0., 0., 0.],</span>
<span class="c1">#  [-0.6333261, -0.0592172, 0.9660671, 0.9580816]],</span>
<span class="c1"># [[-0.4571511, 0.0210018, 0.9151242, 0.9011748],</span>
<span class="c1">#  [0., 0., 0., 0.],</span>
<span class="c1">#  [0., 0., 0., 0.]],</span>
<span class="c1"># [[-0.3585358, 0.0918219, 0.9496037, 0.9391552],</span>
<span class="c1">#  [0., 0., 0., 0.],</span>
<span class="c1">#  [0., 0., 0., 0.]]</span>
<span class="c1"># ]</span>
<span class="c1"># [4 1 2]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="dynamic-rnn">
<h3>Dynamic_RNN<a class="headerlink" href="#dynamic-rnn" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.rnn.Dynamic_RNN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.rnn.</span></span><span class="sig-name descname"><span class="pre">Dynamic_RNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinearity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.rnn.Dynamic_RNN" title="Link to this definition">¶</a></dt>
<dd><p>将循环神经网络 RNN 应用于动态长度输入序列。</p>
<p>第一个输入应该是定义了可变长度的批处理序列输入
通过 <code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类。
<code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类可以构造为
连续调用下一个函数: <code class="docutils literal notranslate"><span class="pre">pad_sequence</span></code> 、 <code class="docutils literal notranslate"><span class="pre">pack_pad_sequence</span></code>。</p>
<p>Dynamic_RNN 的第一个输出也是一个 <code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类,
可以使用 <code class="docutils literal notranslate"><span class="pre">tensor.pad_pack_sequence</span></code> 将其解压缩为普通 QTensor。</p>
<p>循环神经网络(RNN)模块,使用 <span class="math notranslate nohighlight">\(\tanh\)</span> 或 <span class="math notranslate nohighlight">\(\text{ReLU}\)</span> 作为激活函数。支持双向,多层配置。
单层单向RNN计算公式如下:</p>
<div class="math notranslate nohighlight">
\[h_t = \tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\]</div>
<p>如果 <code class="xref py py-attr docutils literal notranslate"><span class="pre">nonlinearity</span></code> 是 <code class="docutils literal notranslate"><span class="pre">'relu'</span></code>, 则 <span class="math notranslate nohighlight">\(\text{ReLU}\)</span> 将替代 <span class="math notranslate nohighlight">\(\tanh\)</span>。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 输入特征维度。</p></li>
<li><p><strong>hidden_size</strong> – 隐藏特征维度。</p></li>
<li><p><strong>num_layers</strong> – 堆叠RNN层数, 默认: 1。</p></li>
<li><p><strong>nonlinearity</strong> – 非线性激活函数,默认为 <code class="docutils literal notranslate"><span class="pre">'tanh'</span></code>。</p></li>
<li><p><strong>batch_first</strong> – 如果为 True, 则输入形状为 [批大小,序列长度,特征维度],
如果为 False, 则输入形状为 [序列长度,批大小,特征维度],默认为 True。</p></li>
<li><p><strong>use_bias</strong> – 如果为 False, 该模块不适用偏置项,默认: True。</p></li>
<li><p><strong>bidirectional</strong> – 如果为 True,变为双向RNN,默认: False。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dynamic_RNN 实例</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dynamic_RNN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">batch_size</span> <span class="o">=</span><span class="mi">3</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ml</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">rnn2</span> <span class="o">=</span> <span class="n">Dynamic_RNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
                <span class="n">hidden_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="kc">False</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">pack_pad_sequence</span><span class="p">(</span><span class="n">y</span><span class="p">,</span>
                                <span class="n">seq_len</span><span class="p">,</span>
                                <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">h0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">ml</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">])</span>

<span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="n">seq_unpacked</span><span class="p">,</span> <span class="n">lens_unpacked</span> <span class="o">=</span> \
<span class="n">tensor</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">seq_unpacked</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lens_unpacked</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[1.2980951, 0., 0., 0.],</span>
<span class="c1">#  [1.5040692, 0., 0., 0.],</span>
<span class="c1">#  [1.4927036, 0., 0., 0.1065927]],</span>
<span class="c1"># [[2.6561704, 0., 0., 0.2532321],</span>
<span class="c1">#  [0., 0., 0., 0.],</span>
<span class="c1">#  [3.1472805, 0., 0., 0.]],</span>
<span class="c1"># [[5.1231661, 0., 0., 0.7596353],</span>
<span class="c1">#  [0., 0., 0., 0.],</span>
<span class="c1">#  [0., 0., 0., 0.]],</span>
<span class="c1"># [[8.4954977, 0., 0., 0.8191229],</span>
<span class="c1">#  [0., 0., 0., 0.],</span>
<span class="c1">#  [0., 0., 0., 0.]]</span>
<span class="c1"># ]</span>
<span class="c1"># [4 1 2]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="dynamic-lstm">
<h3>Dynamic_LSTM<a class="headerlink" href="#dynamic-lstm" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.lstm.Dynamic_LSTM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.lstm.</span></span><span class="sig-name descname"><span class="pre">Dynamic_LSTM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.lstm.Dynamic_LSTM" title="Link to this definition">¶</a></dt>
<dd><p>将长短期记忆(LSTM) RNN 应用于动态长度输入序列。</p>
<p>第一个输入应该是定义了可变长度的批处理序列输入
通过 <code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类。
<code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类可以构造为
连续调用下一个函数: <code class="docutils literal notranslate"><span class="pre">pad_sequence</span></code> 、 <code class="docutils literal notranslate"><span class="pre">pack_pad_sequence</span></code>。</p>
<p>Dynamic_LSTM 的第一个输出也是一个 <code class="docutils literal notranslate"><span class="pre">tensor.PackedSequence</span></code> 类,
可以使用 <code class="docutils literal notranslate"><span class="pre">tensor.pad_pack_sequence</span></code> 将其解压缩为普通 QTensor。</p>
<p>循环神经网络(RNN)模块,使用 <span class="math notranslate nohighlight">\(\tanh\)</span> 或 <span class="math notranslate nohighlight">\(\text{ReLU}\)</span> 作为激活函数。支持双向,多层配置。
单层单向RNN计算公式如下:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll} \\
    i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\
    f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\
    g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\
    o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\
    c_t = f_t \odot c_{t-1} + i_t \odot g_t \\
    h_t = o_t \odot \tanh(c_t) \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 输入特征维度。</p></li>
<li><p><strong>hidden_size</strong> – 隐藏特征维度。</p></li>
<li><p><strong>num_layers</strong> – 堆叠LSTM层数,默认: 1。</p></li>
<li><p><strong>batch_first</strong> – 如果为 True,则输入形状为 [批大小,序列长度,特征维度],
如果为 False, 则输入形状为 [序列长度,批大小,特征维度],默认为 True。</p></li>
<li><p><strong>use_bias</strong> – 如果为 False,该模块不适用偏置项, 默认: True。</p></li>
<li><p><strong>bidirectional</strong> – 如果为 True,变为双向LSTM, 默认: False。</p></li>
<li><p><strong>dtype</strong> – 参数的数据类型,defaults:None,使用默认数据类型:kfloat32,代表32位浮点数。</p></li>
<li><p><strong>name</strong> – 这个模块的名字, 默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dynamic_LSTM 实例</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dynamic_LSTM</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ml</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">rnn2</span> <span class="o">=</span> <span class="n">Dynamic_LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span>
                    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
                    <span class="n">num_layers</span><span class="o">=</span><span class="n">ml</span><span class="p">,</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">[</span><span class="n">seq_len</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">b</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">c</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="kc">False</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">pack_pad_sequence</span><span class="p">(</span><span class="n">y</span><span class="p">,</span>
                                <span class="n">seq_len</span><span class="p">,</span>
                                <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">h0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">ml</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">])</span>
<span class="n">c0</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">ml</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">])</span>

<span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">rnn2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>

<span class="n">seq_unpacked</span><span class="p">,</span> <span class="n">lens_unpacked</span> <span class="o">=</span> \
<span class="n">tensor</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">seq_unpacked</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lens_unpacked</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[0.2038177, 0.1139005, 0.2312966, -0.1140076],</span>
<span class="c1">#  [0.1992285, 0.1221137, 0.2277344, -0.3147154],</span>
<span class="c1">#  [0.2293468, 0.0681745, 0.2426863, 0.2572871]],</span>
<span class="c1"># [[0.1398094, -0.0150359, 0.2513067, 0.0783743],</span>
<span class="c1">#  [0.1328388, -0.0031956, 0.2324090, -0.1962151],</span>
<span class="c1">#  [0., 0., 0., 0.]],</span>
<span class="c1"># [[0.0898260, -0.0706460, 0.2396922, 0.2323916],</span>
<span class="c1">#  [0.0817787, -0.0449937, 0.2388873, -0.0000469],</span>
<span class="c1">#  [0., 0., 0., 0.]],</span>
<span class="c1"># [[0., 0., 0., 0.],</span>
<span class="c1">#  [0.0532839, -0.0870574, 0.2397324, 0.2103822],</span>
<span class="c1">#  [0., 0., 0., 0.]]</span>
<span class="c1"># ]</span>
<span class="c1"># [3 4 1]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="interpolate">
<h3>Interpolate<a class="headerlink" href="#interpolate" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Interpolate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Interpolate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recompute_scale_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Interpolate" title="Link to this definition">¶</a></dt>
<dd><p>向下/向上对输入进行采样。</p>
<p>目前只支持四维输入数据。</p>
<p>输入尺寸的解释形式为 <cite>B x C x H x W</cite>。</p>
<p>可用于选择的 <cite>mode</cite> 有 <code class="docutils literal notranslate"><span class="pre">nearest</span></code> 、<code class="docutils literal notranslate"><span class="pre">bilinear</span></code> 、<code class="docutils literal notranslate"><span class="pre">bicubic</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – 输出大小,默认为None。</p></li>
<li><p><strong>scale_factor</strong> – 缩放因子,默认为None。</p></li>
<li><p><strong>mode</strong> – 用于上采样的算法  <code class="docutils literal notranslate"><span class="pre">nearest</span></code> | <code class="docutils literal notranslate"><span class="pre">bilinear</span></code> | <code class="docutils literal notranslate"><span class="pre">bicubic</span></code>.</p></li>
<li><p><strong>align_corners</strong> – 从几何学角度看,我们将输入和输出的像素点视为方形而不是点。输入和输出的像素点视为正方形,而不是点。
如果设置为 <cite>true</cite>,输入和输出张量将根据其角像素的中心点对齐。角像素的中心点对齐,保留角像素的值。
如果设置为 <cite>false</cite>,输入和输出张量将按其角像素的角点对齐,而角像素的值将保留。角像素的角点对齐,插值会使用边缘值填充
对超出边界的值进行填充,从而使此操作与输入大小无关。
当 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 保持不变时。这只有在 <code class="docutils literal notranslate"><span class="pre">mode</span></code> 为 <code class="docutils literal notranslate"><span class="pre">bilinear</span></code> 时才有效。</p></li>
<li><p><strong>recompute_scale_factor</strong> – 重新计算缩放因子,以便在插值计算中使用。 当 <code class="docutils literal notranslate"><span class="pre">scale_factor</span></code> 作为参数传递时,它将用于来计算输出尺寸。</p></li>
<li><p><strong>name</strong> – 模块名字.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Interpolate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="n">pyvqnet</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">np_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">36</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">mode_</span> <span class="o">=</span> <span class="s2">&quot;bilinear&quot;</span>
<span class="n">size_</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">class</span><span class="w"> </span><span class="nc">model_vqnet</span><span class="p">(</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inter</span> <span class="o">=</span> <span class="n">Interpolate</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">size_</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span>

<span class="n">input_vqnet</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">np_</span><span class="p">,</span>  <span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">loss_pyvqnet</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
<span class="n">output_vqnet</span> <span class="o">=</span> <span class="n">model_vqnet</span><span class="p">(</span><span class="n">input_vqnet</span><span class="p">)</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">loss_pyvqnet</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]]),</span> <span class="n">output_vqnet</span><span class="p">)</span>
<span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="fuse-module">
<h3>fuse_module<a class="headerlink" href="#fuse-module" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.fuse_module">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">fuse_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.fuse_module" title="Link to this definition">¶</a></dt>
<dd><p>用于模型在推理阶段的相应相邻模块融合成一个模块,减少模型推理阶段计算量, 增加模型推理速度。</p>
<p>目前支持的模块序列如下:</p>
<p>conv, bn</p>
<p>linear, bn</p>
<p>其他序列保持不变,对于这些序列将列表中的第一个模块替换成融合后的模块,其他的用 <code class="docutils literal notranslate"><span class="pre">Identity</span></code> 代替。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> – 包括融合模块的模型。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>模块融合后的模型。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">BatchNorm1d</span><span class="p">,</span> <span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">Conv2D</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.qnn.vqc</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span><span class="n">BinaryCrossEntropy</span><span class="p">,</span> <span class="n">Sigmoid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_generator</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">set_random_seed</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">fuse_module</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_accuary</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">result</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">sums</span><span class="p">(</span><span class="n">result</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">score</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ban</span> <span class="o">=</span> <span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">li1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ac</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ban</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">li1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ac</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">80</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">80</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">BinaryCrossEntropy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start training..............&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accuracy_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">time2</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sum_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">accuary</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">data_generator</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">toGPU</span><span class="p">(),</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">label</span><span class="p">,</span>
                                            <span class="n">dtype</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                                            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">loss_b</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">result</span><span class="p">)</span>

        <span class="n">loss_b</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>

        <span class="n">sum_loss</span> <span class="o">+=</span> <span class="n">loss_b</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="n">batch_size</span>
        <span class="n">accuary</span> <span class="o">+=</span> <span class="n">get_accuary</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sum_loss</span><span class="o">/</span><span class="n">count</span><span class="p">)</span>
    <span class="n">accuracy_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuary</span><span class="o">/</span><span class="n">count</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;epoch:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, #### loss:</span><span class="si">{</span><span class="n">sum_loss</span><span class="o">/</span><span class="n">count</span><span class="si">}</span><span class="s2"> #####accuray:</span><span class="si">{</span><span class="n">accuary</span><span class="o">/</span><span class="n">count</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;run time </span><span class="si">{</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">()))</span>
<span class="n">time_a</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;fuse before </span><span class="si">{</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_a</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">fuse_module</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">()))</span>
<span class="n">time_b</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;fuse after </span><span class="si">{</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_b</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="sdpa">
<h3>SDPA<a class="headerlink" href="#sdpa" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.transformer.SDPA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.transformer.</span></span><span class="sig-name descname"><span class="pre">SDPA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attn_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_causal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.transformer.SDPA" title="Link to this definition">¶</a></dt>
<dd><p>构造计算查询、键和值张量的缩放点积注意力的类。如果输入为cpu下的QTensor,则使用数学公式计算, 如果输入在gpu下QTensor,则使用flash-attention方法计算。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attn_mask</strong> – 注意力掩码；形状必须可以广播到注意力权重的形状。</p></li>
<li><p><strong>dropout_p</strong> – Dropout 概率,如果大于 0.0, 则应用。</p></li>
<li><p><strong>scale</strong> – 在 softmax 之前应用的缩放因子。</p></li>
<li><p><strong>is_causal</strong> – 如果为 “true”,则假定存在左上因果注意屏蔽,如果同时设置了 attn_mask 和 is_causal, 则会出现错误。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个SDPA类</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.transformer</span><span class="w"> </span><span class="kn">import</span> <span class="n">SDPA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SDPA</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.transformer.SDPA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.transformer.SDPA.forward" title="Link to this definition">¶</a></dt>
<dd><p>进行前向计算,如果输入为cpu下的QTensor,则使用数学公式计算, 如果输入在gpu下QTensor,则使用flash-attention方法计算。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – query输入QTensor。</p></li>
<li><p><strong>key</strong> – key输入QTensor。</p></li>
<li><p><strong>value</strong> – key输入QTensor。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SDPA计算返回的QTensor。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.transformer</span><span class="w"> </span><span class="kn">import</span> <span class="n">SDPA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SDPA</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>

<span class="n">query_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">key_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">value_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">query_p</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">query_np</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
<span class="n">key_p</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">key_np</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>
<span class="n">value_p</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">value_np</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">kfloat32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">toGPU</span><span class="p">()</span>

<span class="n">out_sdpa</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">query_p</span><span class="p">,</span> <span class="n">key_p</span><span class="p">,</span> <span class="n">value_p</span><span class="p">)</span>

<span class="n">out_sdpa</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="id7">
<h2>损失函数层<a class="headerlink" href="#id7" title="Link to this heading">¶</a></h2>
<p>以下为神经网络常用的损失层。</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,以下loss函数的前向函数中,第一个参数为标签,第二个参数为预测值。</p>
</div>
</div></blockquote>
<section id="meansquarederror">
<h3>MeanSquaredError<a class="headerlink" href="#meansquarederror" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.MeanSquaredError">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">MeanSquaredError</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.MeanSquaredError" title="Link to this definition">¶</a></dt>
<dd><p>计算输入 <span class="math notranslate nohighlight">\(x\)</span> 和目标值 <span class="math notranslate nohighlight">\(y\)</span> 之间的均方根误差。</p>
<p>若平方根误差可由如下函数描述:</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = \left( x_n - y_n \right)^2,\]</div>
<p><span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 是任意形状的 QTensor , 总 <span class="math notranslate nohighlight">\(n\)</span> 个元素的均方根误差由下式计算。</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) =
    \operatorname{mean}(L)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 这个模块的名字, 默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个均方根误差实例。</p>
</dd>
</dl>
<p>均方根误差前向计算函数的所需参数:</p>
<blockquote>
<div><p>x: <span class="math notranslate nohighlight">\((N, *)\)</span> 预测值,其中 <span class="math notranslate nohighlight">\(*\)</span> 表示任意维度。</p>
<p>y: <span class="math notranslate nohighlight">\((N, *)\)</span>, 目标值, 和输入一样维度的 QTensor 。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,以下MeanSquaredError函数的前向函数中,第一个参数为目标值,第二个参数为预测值。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kfloat64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">MeanSquaredError</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">kfloat64</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">kfloat64</span><span class="p">)</span>

<span class="n">loss_result</span> <span class="o">=</span> <span class="n">MeanSquaredError</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">loss_result</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># [0.0115000]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="binarycrossentropy">
<h3>BinaryCrossEntropy<a class="headerlink" href="#binarycrossentropy" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.BinaryCrossEntropy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">BinaryCrossEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.BinaryCrossEntropy" title="Link to this definition">¶</a></dt>
<dd><p>测量目标和输入之间的平均二元交叉熵损失。</p>
<p>未做平均运算的二元交叉熵如下式:</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right],\]</div>
<p>若 <span class="math notranslate nohighlight">\(N\)</span> 为批的大小,则平均二元交叉熵.</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) = \operatorname{mean}(L)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 这个模块的名字, 默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个平均二元交叉熵实例。</p>
</dd>
</dl>
<p>平均二元交叉熵误差前向计算函数的所需参数:</p>
<blockquote>
<div><p>x: <span class="math notranslate nohighlight">\((N, *)\)</span> 预测值,其中 <span class="math notranslate nohighlight">\(*\)</span> 表示任意维度。</p>
<p>y: <span class="math notranslate nohighlight">\((N, *)\)</span>, 目标值,和输入一样维度的 QTensor 。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,BinaryCrossEntropy函数的前向函数中,第一个参数为目标值,第二个参数为预测值。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">BinaryCrossEntropy</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">loss_result</span> <span class="o">=</span> <span class="n">BinaryCrossEntropy</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">loss_result</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># [0.6364825]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="categoricalcrossentropy">
<h3>CategoricalCrossEntropy<a class="headerlink" href="#categoricalcrossentropy" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.CategoricalCrossEntropy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">CategoricalCrossEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.CategoricalCrossEntropy" title="Link to this definition">¶</a></dt>
<dd><p>该损失函数将 LogSoftmax 和 NLLLoss 同时计算的平均分类交叉熵。</p>
<p>损失函数计算方式如下,其中 class 为目标值的对应分类标签:</p>
<div class="math notranslate nohighlight">
\[\text{loss}(x, y) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)
               = -x[class] + \log\left(\sum_j \exp(x[j])\right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 这个模块的名字, 默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>平均分类交叉熵实例。</p>
</dd>
</dl>
<p>误差前向计算函数的所需参数:</p>
<blockquote>
<div><p>x: <span class="math notranslate nohighlight">\((N, *)\)</span> 预测值,其中 <span class="math notranslate nohighlight">\(*\)</span> 表示任意维度。</p>
<p>y: <span class="math notranslate nohighlight">\((N, *)\)</span>, 目标值,和输入一样维度的 QTensor 。必须为64位整数,kint64。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,CategoricalCrossEntropy函数的前向函数中,第一个参数为目标值,第二个参数为预测值。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kfloat32</span><span class="p">,</span><span class="n">kint64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">CategoricalCrossEntropy</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">kint64</span><span class="p">)</span>
<span class="n">loss_result</span> <span class="o">=</span> <span class="n">CategoricalCrossEntropy</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">loss_result</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># [3.7852428]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="softmaxcrossentropy">
<h3>SoftmaxCrossEntropy<a class="headerlink" href="#softmaxcrossentropy" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.SoftmaxCrossEntropy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">SoftmaxCrossEntropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.SoftmaxCrossEntropy" title="Link to this definition">¶</a></dt>
<dd><p>该损失函数将 LogSoftmax 和 NLLLoss 同时计算的平均分类交叉熵,并具有更高的数值稳定性。</p>
<p>损失函数计算方式如下,其中 class 为目标值的对应分类标签:</p>
<div class="math notranslate nohighlight">
\[\text{loss}(x, y) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)
               = -x[class] + \log\left(\sum_j \exp(x[j])\right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 这个模块的名字, 默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个Softmax交叉熵损失函数实例</p>
</dd>
</dl>
<p>误差前向计算函数的所需参数:</p>
<blockquote>
<div><p>x: <span class="math notranslate nohighlight">\((N, *)\)</span> 预测值,其中 <span class="math notranslate nohighlight">\(*\)</span> 表示任意维度。</p>
<p>y: <span class="math notranslate nohighlight">\((N, *)\)</span>, 目标值,和输入一样维度的 QTensor 。必须为64位整数,kint64。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,SoftmaxCrossEntropy函数的前向函数中,第一个参数为目标值,第二个参数为预测值。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kfloat32</span><span class="p">,</span> <span class="n">kint64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">SoftmaxCrossEntropy</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">kfloat32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">kint64</span><span class="p">)</span>
<span class="n">loss_result</span> <span class="o">=</span> <span class="n">SoftmaxCrossEntropy</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">loss_result</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># [3.7852478]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="nll-loss">
<h3>NLL_Loss<a class="headerlink" href="#nll-loss" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.NLL_Loss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">NLL_Loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.NLL_Loss" title="Link to this definition">¶</a></dt>
<dd><p>平均负对数似然损失。 对C个类别的分类问题很有用。</p>
<p><cite>x</cite> 是模型给出的概率形式的似然量。其尺寸可以是 <span class="math notranslate nohighlight">\((N, C)\)</span> or <span class="math notranslate nohighlight">\((N, C, d_1, d_2, ..., d_K)\)</span> 。 <cite>y</cite> 是损失函数期望的真值,包含 <span class="math notranslate nohighlight">\([0, C-1]\)</span> 的类别索引。</p>
<div class="math notranslate nohighlight">
\[\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = -
    \sum_{n=1}^N \frac{1}{N}x_{n,y_n} \quad\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 这个模块的名字, 默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个NLL_Loss损失函数实例</p>
</dd>
</dl>
<p>误差前向计算函数的所需参数:</p>
<blockquote>
<div><p>x: <span class="math notranslate nohighlight">\((N, *)\)</span>,损失函数的输出预测值,可以为多维变量。</p>
<p>y: <span class="math notranslate nohighlight">\((N, *)\)</span>,损失函数目标值。必须为64位整数,kint64。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,NLL_Loss函数的前向函数中,第一个参数为目标值,第二个参数为预测值。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kint64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">NLL_Loss</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([</span>
    <span class="mf">0.9476322568516703</span><span class="p">,</span> <span class="mf">0.226547421131723</span><span class="p">,</span> <span class="mf">0.5944201443911326</span><span class="p">,</span>
    <span class="mf">0.42830868492969476</span><span class="p">,</span> <span class="mf">0.76414068655387</span><span class="p">,</span> <span class="mf">0.00286059168094277</span><span class="p">,</span>
    <span class="mf">0.3574236812873617</span><span class="p">,</span> <span class="mf">0.9096948856639084</span><span class="p">,</span> <span class="mf">0.4560809854582528</span><span class="p">,</span>
    <span class="mf">0.9818027091583286</span><span class="p">,</span> <span class="mf">0.8673569904602182</span><span class="p">,</span> <span class="mf">0.9860275114020933</span><span class="p">,</span>
    <span class="mf">0.9232667066664217</span><span class="p">,</span> <span class="mf">0.303693313961628</span><span class="p">,</span> <span class="mf">0.8461034903175555</span>
<span class="p">])</span>
<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">kint64</span><span class="p">)</span>

<span class="n">loss_result</span> <span class="o">=</span> <span class="n">NLL_Loss</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">loss_result</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1">#[-0.6187226]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="crossentropyloss">
<h3>CrossEntropyLoss<a class="headerlink" href="#crossentropyloss" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.CrossEntropyLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">CrossEntropyLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.CrossEntropyLoss" title="Link to this definition">¶</a></dt>
<dd><p>该函数计算LogSoftmax以及NLL_Loss在一起的损失。</p>
<p><cite>x</cite> 是包含未做归一化的输出.它的尺寸可以为 <span class="math notranslate nohighlight">\((C)\)</span> , <span class="math notranslate nohighlight">\((N, C)\)</span> 二维或 <span class="math notranslate nohighlight">\((N, C, d_1, d_2, ..., d_K)\)</span> 多维。</p>
<p>损失函数的公式如下,其中 class 为目标值的对应分类标签:</p>
<div class="math notranslate nohighlight">
\[\text{loss}(x, y) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)
               = -x[class] + \log\left(\sum_j \exp(x[j])\right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 这个模块的名字, 默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个CrossEntropyLoss损失函数实例</p>
</dd>
</dl>
<p>误差前向计算函数的所需参数:</p>
<blockquote>
<div><p>x: <span class="math notranslate nohighlight">\((N, *)\)</span>,损失函数的输出,可以为多维变量。</p>
<p>y: <span class="math notranslate nohighlight">\((N, *)\)</span>,损失函数期望的真值。必须为64位整数,kint64。</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意,跟pytorch等框架不同的是,CrossEntropyLoss函数的前向函数中,第一个参数为目标值,第二个参数为预测值。</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span><span class="p">,</span> <span class="n">kint64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">CrossEntropyLoss</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([</span>
    <span class="mf">0.9476322568516703</span><span class="p">,</span> <span class="mf">0.226547421131723</span><span class="p">,</span> <span class="mf">0.5944201443911326</span><span class="p">,</span>
    <span class="mf">0.42830868492969476</span><span class="p">,</span> <span class="mf">0.76414068655387</span><span class="p">,</span> <span class="mf">0.00286059168094277</span><span class="p">,</span>
    <span class="mf">0.3574236812873617</span><span class="p">,</span> <span class="mf">0.9096948856639084</span><span class="p">,</span> <span class="mf">0.4560809854582528</span><span class="p">,</span>
    <span class="mf">0.9818027091583286</span><span class="p">,</span> <span class="mf">0.8673569904602182</span><span class="p">,</span> <span class="mf">0.9860275114020933</span><span class="p">,</span>
    <span class="mf">0.9232667066664217</span><span class="p">,</span> <span class="mf">0.303693313961628</span><span class="p">,</span> <span class="mf">0.8461034903175555</span>
<span class="p">])</span>
<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">kint64</span><span class="p">)</span>

<span class="n">loss_result</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">loss_result</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1">#[1.1508200]</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="id8">
<h2>激活函数<a class="headerlink" href="#id8" title="Link to this heading">¶</a></h2>
<section id="activation">
<h3>Activation<a class="headerlink" href="#activation" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.activation.Activation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.activation.</span></span><span class="sig-name descname"><span class="pre">Activation</span></span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.activation.Activation" title="Link to this definition">¶</a></dt>
<dd><p>激活的基类。 特定的激活函数继承了这个类。</p>
</dd></dl>

</section>
<section id="sigmoid">
<h3>Sigmoid<a class="headerlink" href="#sigmoid" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Sigmoid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Sigmoid" title="Link to this definition">¶</a></dt>
<dd><p>Sigmoid激活函数层。</p>
<div class="math notranslate nohighlight">
\[\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 激活函数层的命名,默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个Sigmoid激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sigmoid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [0.7310586, 0.8807970, 0.9525741, 0.9820138]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="softplus">
<h3>Softplus<a class="headerlink" href="#softplus" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Softplus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Softplus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Softplus" title="Link to this definition">¶</a></dt>
<dd><p>Softplus激活函数层。</p>
<div class="math notranslate nohighlight">
\[\text{Softplus}(x) = \log(1 + \exp(x))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 激活函数层的命名,默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个Softplus激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Softplus</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">Softplus</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [1.3132616, 2.1269281, 3.0485873, 4.0181499]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="softsign">
<h3>Softsign<a class="headerlink" href="#softsign" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Softsign">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Softsign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Softsign" title="Link to this definition">¶</a></dt>
<dd><p>Softsign 激活函数层。</p>
<div class="math notranslate nohighlight">
\[\text{SoftSign}(x) = \frac{x}{ 1 + |x|}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 激活函数层的命名,默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个Softsign 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Softsign</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">Softsign</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [0.5000000, 0.6666667, 0.7500000, 0.8000000]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="softmax">
<h3>Softmax<a class="headerlink" href="#softmax" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Softmax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Softmax" title="Link to this definition">¶</a></dt>
<dd><p>Softmax 激活函数层。</p>
<div class="math notranslate nohighlight">
\[\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> – 计算的维度(最后一个轴为-1),默认值 = -1。</p></li>
<li><p><strong>name</strong> – 激活函数层的命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个Softmax 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Softmax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">Softmax</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [0.0320586, 0.0871443, 0.2368828, 0.6439142]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="hardsigmoid">
<h3>HardSigmoid<a class="headerlink" href="#hardsigmoid" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.HardSigmoid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">HardSigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.HardSigmoid" title="Link to this definition">¶</a></dt>
<dd><p>HardSigmoid 激活函数层。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{Hardsigmoid}(x) = \begin{cases}
    0 &amp; \text{ if } x \le -3, \\
    1 &amp; \text{ if } x \ge +3, \\
    x / 6 + 1 / 2 &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 激活函数层的命名,默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个HardSigmoid 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">HardSigmoid</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">HardSigmoid</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [0.6666667, 0.8333334, 1., 1.]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="relu">
<h3>ReLu<a class="headerlink" href="#relu" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.ReLu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">ReLu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.ReLu" title="Link to this definition">¶</a></dt>
<dd><p>ReLu 整流线性单元激活函数层。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{ReLu}(x) = \begin{cases}
x, &amp; \text{ if } x &gt; 0\\
0, &amp; \text{ if } x \leq 0
\end{cases}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 激活函数层的命名,默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个ReLu 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReLu</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">ReLu</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [0., 2., 0., 4.]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="leakyrelu">
<h3>LeakyReLu<a class="headerlink" href="#leakyrelu" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.LeakyReLu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">LeakyReLu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.LeakyReLu" title="Link to this definition">¶</a></dt>
<dd><p>LeakyReLu 带泄露的修正线性单元激活函数层。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{LeakyRelu}(x) =
\begin{cases}
x, &amp; \text{ if } x \geq 0 \\
\alpha * x, &amp; \text{ otherwise }
\end{cases}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> – LeakyRelu 系数,默认:0.01。</p></li>
<li><p><strong>name</strong> – 激活函数层的命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个LeakyReLu 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">LeakyReLu</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">LeakyReLu</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [-0.0100000, 2., -0.0300000, 4.]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="gelu">
<h3>Gelu<a class="headerlink" href="#gelu" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Gelu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Gelu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Gelu" title="Link to this definition">¶</a></dt>
<dd><p>应用高斯误差线性单元函数:</p>
<div class="math notranslate nohighlight">
\[\text{GELU}(x) = x * \Phi(x)\]</div>
<p>当近似参数为 ‘tanh’ 时, GELU 通过以下方式估计:</p>
<div class="math notranslate nohighlight">
\[\text{GELU}(x) = 0.5 * x * (1 + \text{Tanh}(\sqrt{2 / \pi} * (x + 0.044715 * x^3)))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>approximate</strong> – 近似计算方式, 默认为”tanh”。</p></li>
<li><p><strong>name</strong> – 激活函数层的命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gelu 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">randu</span><span class="p">,</span> <span class="n">ones_like</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Gelu</span>
<span class="n">qa</span> <span class="o">=</span> <span class="n">randu</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">qb</span> <span class="o">=</span> <span class="n">Gelu</span><span class="p">()(</span><span class="n">qa</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">qb</span><span class="p">)</span>
<span class="c1"># [[0.0292515,0.0668998,0.4036024,0.8369502],</span>
<span class="c1">#  [0.1929213,0.1981275,0.2358531,0.7790835],</span>
<span class="c1">#  [0.1754935,0.6204091,0.2354677,0.2409406],</span>
<span class="c1">#  [0.4238827,0.804715 ,0.1633414,0.2853   ],</span>
<span class="c1">#  [0.1959854,0.590143 ,0.553995 ,0.0008423]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="elu">
<h3>ELU<a class="headerlink" href="#elu" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.ELU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">ELU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.ELU" title="Link to this definition">¶</a></dt>
<dd><p>ELU 指数线性单位激活函数层。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{ELU}(x) = \begin{cases}
x, &amp; \text{ if } x &gt; 0\\
\alpha * (\exp(x) - 1), &amp; \text{ if } x \leq 0
\end{cases}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> – ELU 系数,默认:1。</p></li>
<li><p><strong>name</strong> – 激活函数层的命名,默认为””。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ELU 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">ELU</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">ELU</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [-0.6321205, 2., -0.9502130, 4.]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="tanh">
<h3>Tanh<a class="headerlink" href="#tanh" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.nn.Tanh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.nn.</span></span><span class="sig-name descname"><span class="pre">Tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.nn.Tanh" title="Link to this definition">¶</a></dt>
<dd><p>Tanh双曲正切激活函数.</p>
<div class="math notranslate nohighlight">
\[\text{Tanh}(x) = \frac{\exp(x) - \exp(-x)} {\exp(x) + \exp(-x)}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – 激活函数层的命名,默认为””。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tanh 激活函数层实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tanh</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">Tanh</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">QTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># [-0.7615942, 0.9640276, -0.9950548, 0.9993293]</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="id9">
<h2>优化器模块<a class="headerlink" href="#id9" title="Link to this heading">¶</a></h2>
<section id="optimizer">
<span id="id10"></span><h3>Optimizer<a class="headerlink" href="#optimizer" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.optimizer.Optimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.optimizer.</span></span><span class="sig-name descname"><span class="pre">Optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.optimizer.Optimizer" title="Link to this definition">¶</a></dt>
<dd><p>所有优化器的基类。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率,默认值:0.01。</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="adadelta">
<h3>Adadelta<a class="headerlink" href="#adadelta" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.adadelta.Adadelta">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.adadelta.</span></span><span class="sig-name descname"><span class="pre">Adadelta</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.adadelta.Adadelta" title="Link to this definition">¶</a></dt>
<dd><p>ADADELTA: An Adaptive Learning Rate Method。</p>
<p>参考:<a class="reference external" href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}E(g_t^2) &amp;= \beta * E(g_{t-1}^2) + (1-\beta) * g^2\\
Square\_avg &amp;= \sqrt{ ( E(dx_{t-1}^2) + \epsilon ) / ( E(g_t^2) + \epsilon ) }\\
E(dx_t^2) &amp;= \beta * E(dx_{t-1}^2) + (1-\beta) * (-g*square\_avg)^2 \\
param\_new &amp;= param - lr * Square\_avg\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>beta</strong> – 用于计算平方梯度的运行平均值(默认值:0.99)。</p></li>
<li><p><strong>epsilon</strong> – 添加到分母以提高数值稳定性的常数(默认值:1e-8)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 Adadelta 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">adadelta</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">adadelta</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9999900, 1.9999900, 2.9999900],</span>
<span class="c1">#  [3.9999900, 4.9999900, 5.9999900, 6.9999900],</span>
<span class="c1">#  [7.9999900, 8.9999905, 9.9999905, 10.9999905]],</span>
<span class="c1"># [[11.9999905, 12.9999905, 13.9999905, 14.9999905],</span>
<span class="c1">#  [15.9999905, 16.9999905, 17.9999905, 18.9999905],</span>
<span class="c1">#  [19.9999905, 20.9999905, 21.9999905, 22.9999905]]]</span>
<span class="c1"># ]</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9999800, 1.9999800, 2.9999800],</span>
<span class="c1">#  [3.9999800, 4.9999800, 5.9999800, 6.9999800],</span>
<span class="c1">#  [7.9999800, 8.9999800, 9.9999800, 10.9999800]],</span>
<span class="c1"># [[11.9999800, 12.9999800, 13.9999800, 14.9999800],</span>
<span class="c1">#  [15.9999800, 16.9999809, 17.9999809, 18.9999809],</span>
<span class="c1">#  [19.9999809, 20.9999809, 21.9999809, 22.9999809]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="adagrad">
<h3>Adagrad<a class="headerlink" href="#adagrad" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.adagrad.Adagrad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.adagrad.</span></span><span class="sig-name descname"><span class="pre">Adagrad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.adagrad.Adagrad" title="Link to this definition">¶</a></dt>
<dd><p>Adagrad自适应梯度优化器。</p>
<p>参考:<a class="reference external" href="https://databricks.com/glossary/adagrad">https://databricks.com/glossary/adagrad</a>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
moment\_new &amp;= moment + g * g\\param\_new
&amp;= param - \frac{lr * g}{\sqrt{moment\_new} + \epsilon}
\end{align}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>epsilon</strong> – 添加到分母以提高数值稳定性的常数(默认值:1e-8)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 Adagrad 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">adagrad</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">adagrad</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9900000, 1.9900000, 2.9900000],</span>
<span class="c1">#  [3.9900000, 4.9899998, 5.9899998, 6.9899998],</span>
<span class="c1">#  [7.9899998, 8.9899998, 9.9899998, 10.9899998]],</span>
<span class="c1"># [[11.9899998, 12.9899998, 13.9899998, 14.9899998],</span>
<span class="c1">#  [15.9899998, 16.9899998, 17.9899998, 18.9899998],</span>
<span class="c1">#  [19.9899998, 20.9899998, 21.9899998, 22.9899998]]]</span>
<span class="c1"># ]</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9829289, 1.9829290, 2.9829290],</span>
<span class="c1">#  [3.9829290, 4.9829288, 5.9829288, 6.9829288],</span>
<span class="c1">#  [7.9829288, 8.9829283, 9.9829283, 10.9829283]],</span>
<span class="c1"># [[11.9829283, 12.9829283, 13.9829283, 14.9829283],</span>
<span class="c1">#  [15.9829283, 16.9829292, 17.9829292, 18.9829292],</span>
<span class="c1">#  [19.9829292, 20.9829292, 21.9829292, 22.9829292]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="adam">
<h3>Adam<a class="headerlink" href="#adam" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.adam.Adam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.adam.</span></span><span class="sig-name descname"><span class="pre">Adam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amsgrad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.adam.Adam" title="Link to this definition">¶</a></dt>
<dd><p>Adam优化器,它可以使用一阶矩估计动态调整每个参数的学习率和梯度的二阶矩估计。</p>
<p>参考:<a class="reference external" href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>。</p>
<div class="math notranslate nohighlight">
\[t = t + 1\]</div>
<div class="math notranslate nohighlight">
\[param  = param - lr*weight\_decay*param\]</div>
<div class="math notranslate nohighlight">
\[moment\_1\_new=\beta1∗moment\_1+(1−\beta1)g\]</div>
<div class="math notranslate nohighlight">
\[moment\_2\_new=\beta2∗moment\_2+(1−\beta2)g*g\]</div>
<div class="math notranslate nohighlight">
\[lr = lr*\frac{\sqrt{1-\beta2^t}}{1-\beta1^t}\]</div>
<p>如果参数 amsgrad 为 True</p>
<div class="math notranslate nohighlight">
\[moment\_2\_max = max(moment\_2\_max,moment\_2)\]</div>
<div class="math notranslate nohighlight">
\[param\_new=param-lr*\frac{moment\_1}{\sqrt{moment\_2\_max}+\epsilon}\]</div>
<p>否则</p>
<div class="math notranslate nohighlight">
\[param\_new=param-lr*\frac{moment\_1}{\sqrt{moment\_2}+\epsilon}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>beta1</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.9)。</p></li>
<li><p><strong>beta2</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.999)。</p></li>
<li><p><strong>epsilon</strong> – 添加到分母以提高数值稳定性的常数(默认值:1e-8)。</p></li>
<li><p><strong>amsgrad</strong> – 是否使用该算法的 AMSGrad 变体(默认值:False)。</p></li>
<li><p><strong>weight_decay</strong> – 权重衰减系数(默认值0)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 Adam 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">adam</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9900000, 1.9900000, 2.9900000],</span>
<span class="c1">#  [3.9900000, 4.9899998, 5.9899998, 6.9899998],</span>
<span class="c1">#  [7.9899998, 8.9899998, 9.9899998, 10.9899998]],</span>
<span class="c1"># [[11.9899998, 12.9899998, 13.9899998, 14.9899998],</span>
<span class="c1">#  [15.9899998, 16.9899998, 17.9899998, 18.9899998],</span>
<span class="c1">#  [19.9899998, 20.9899998, 21.9899998, 22.9899998]]]</span>
<span class="c1"># ]</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9800000, 1.9800000, 2.9800000],</span>
<span class="c1">#  [3.9800000, 4.9799995, 5.9799995, 6.9799995],</span>
<span class="c1">#  [7.9799995, 8.9799995, 9.9799995, 10.9799995]],</span>
<span class="c1"># [[11.9799995, 12.9799995, 13.9799995, 14.9799995],</span>
<span class="c1">#  [15.9799995, 16.9799995, 17.9799995, 18.9799995],</span>
<span class="c1">#  [19.9799995, 20.9799995, 21.9799995, 22.9799995]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="adamw">
<h3>AdamW<a class="headerlink" href="#adamw" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.adam.AdamW">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.adam.</span></span><span class="sig-name descname"><span class="pre">AdamW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amsgrad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.adam.AdamW" title="Link to this definition">¶</a></dt>
<dd><p>实现 AdamW 算法.</p>
<div class="math notranslate nohighlight">
\[t = t + 1\]</div>
<div class="math notranslate nohighlight">
\[param\_new  = param - lr*weight\_decay*param\]</div>
<div class="math notranslate nohighlight">
\[moment\_1\_new=\beta1∗moment\_1+(1−\beta1)g\]</div>
<div class="math notranslate nohighlight">
\[moment\_2\_new=\beta2∗moment\_2+(1−\beta2)g*g\]</div>
<div class="math notranslate nohighlight">
\[lr = lr*\frac{\sqrt{1-\beta2^t}}{1-\beta1^t}\]</div>
<p>如果参数 amsgrad 为 True</p>
<div class="math notranslate nohighlight">
\[moment\_2\_max = max(moment\_2\_max,moment\_2)\]</div>
<div class="math notranslate nohighlight">
\[param\_new=param\_new-lr*\frac{moment\_1}{\sqrt{moment\_2\_max}+\epsilon}\]</div>
<p>否则</p>
<div class="math notranslate nohighlight">
\[param\_new=param\_new-lr*\frac{moment\_1}{\sqrt{moment\_2}+\epsilon}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>beta1</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.9)。</p></li>
<li><p><strong>beta2</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.999)。</p></li>
<li><p><strong>epsilon</strong> – 添加到分母以提高数值稳定性的常数(默认值:1e-8)。</p></li>
<li><p><strong>weight_decay</strong> – 权重衰减系数,默认0.01。</p></li>
<li><p><strong>amsgrad</strong> – 是否使用该算法的 AMSGrad 变体(默认值:False)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 AdamW 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">adam</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">adam</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<span class="c1"># [[[[ 0.       ,-0.007475 , 0.98255  , 1.972575 ],</span>
<span class="c1">#    [ 2.9626   , 3.952625 , 4.9426501, 5.9326751],</span>
<span class="c1">#    [ 6.9227001, 7.9127251, 8.9027501, 9.8927751]],</span>

<span class="c1">#   [[10.8828001,11.8728251,12.8628501,13.8528751],</span>
<span class="c1">#    [14.8429002,15.8329252,16.8229502,17.8129752],</span>
<span class="c1">#    [18.8030002,19.7930252,20.7830502,21.7730752]]]]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="adamax">
<h3>Adamax<a class="headerlink" href="#adamax" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.adamax.Adamax">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.adamax.</span></span><span class="sig-name descname"><span class="pre">Adamax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.9</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.adamax.Adamax" title="Link to this definition">¶</a></dt>
<dd><p>实现 Adamax 优化器(基于无穷范数的 Adam 变体)。</p>
<p>参考:<a class="reference external" href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\t = t + 1\end{split}\]</div>
<div class="math notranslate nohighlight">
\[moment\_new=\beta1∗moment+(1−\beta1)g\]</div>
<div class="math notranslate nohighlight">
\[norm\_new = \max{(\beta1∗norm+\epsilon, \left|g\right|)}\]</div>
<div class="math notranslate nohighlight">
\[lr = \frac{lr}{1-\beta1^t}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}param\_new = param − lr*\frac{moment\_new}{norm\_new}\\\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>beta1</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.9)。</p></li>
<li><p><strong>beta2</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.999)。</p></li>
<li><p><strong>epsilon</strong> – 添加到分母以提高数值稳定性的常数(默认值:1e-8)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 Adamax 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">adamax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">adamax</span><span class="o">.</span><span class="n">Adamax</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9900000, 1.9900000, 2.9900000],</span>
<span class="c1">#  [3.9900000, 4.9899998, 5.9899998, 6.9899998],</span>
<span class="c1">#  [7.9899998, 8.9899998, 9.9899998, 10.9899998]],</span>
<span class="c1"># [[11.9899998, 12.9899998, 13.9899998, 14.9899998],</span>
<span class="c1">#  [15.9899998, 16.9899998, 17.9899998, 18.9899998],</span>
<span class="c1">#  [19.9899998, 20.9899998, 21.9899998, 22.9899998]]]</span>
<span class="c1"># ]</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9800000, 1.9800000, 2.9800000],</span>
<span class="c1">#  [3.9800000, 4.9799995, 5.9799995, 6.9799995],</span>
<span class="c1">#  [7.9799995, 8.9799995, 9.9799995, 10.9799995]],</span>
<span class="c1"># [[11.9799995, 12.9799995, 13.9799995, 14.9799995],</span>
<span class="c1">#  [15.9799995, 16.9799995, 17.9799995, 18.9799995],</span>
<span class="c1">#  [19.9799995, 20.9799995, 21.9799995, 22.9799995]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="rmsprop">
<h3>RMSProp<a class="headerlink" href="#rmsprop" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.rmsprop.RMSProp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.rmsprop.</span></span><span class="sig-name descname"><span class="pre">RMSProp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-8</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.rmsprop.RMSProp" title="Link to this definition">¶</a></dt>
<dd><p>RMSprop 均方根传播算法优化器。</p>
<p>参考:<a class="reference external" href="https://arxiv.org/pdf/1308.0850v5.pdf">https://arxiv.org/pdf/1308.0850v5.pdf</a>。</p>
<div class="math notranslate nohighlight">
\[s_{t+1} = s_{t} + (1 - \beta)*(g)^2\]</div>
<div class="math notranslate nohighlight">
\[param_new = param -  \frac{g}{\sqrt{s_{t+1}} + epsilon}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>beta</strong> – 用于计算梯度及其平方的运行平均值的系数(默认值:0.99)。</p></li>
<li><p><strong>epsilon</strong> – 添加到分母以提高数值稳定性的常数(默认值:1e-8)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 RMSProp 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">rmsprop</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">rmsprop</span><span class="o">.</span><span class="n">RMSProp</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9000000, 1.9000000, 2.8999999],</span>
<span class="c1">#  [3.8999999, 4.9000001, 5.9000001, 6.9000001],</span>
<span class="c1">#  [7.9000001, 8.8999996, 9.8999996, 10.8999996]],</span>
<span class="c1"># [[11.8999996, 12.8999996, 13.8999996, 14.8999996],</span>
<span class="c1">#  [15.8999996, 16.8999996, 17.8999996, 18.8999996],</span>
<span class="c1">#  [19.8999996, 20.8999996, 21.8999996, 22.8999996]]]</span>
<span class="c1"># ]</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.8291118, 1.8291118, 2.8291118],</span>
<span class="c1">#  [3.8291118, 4.8291121, 5.8291121, 6.8291121],</span>
<span class="c1">#  [7.8291121, 8.8291111, 9.8291111, 10.8291111]],</span>
<span class="c1"># [[11.8291111, 12.8291111, 13.8291111, 14.8291111],</span>
<span class="c1">#  [15.8291111, 16.8291111, 17.8291111, 18.8291111],</span>
<span class="c1">#  [19.8291111, 20.8291111, 21.8291111, 22.8291111]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="sgd">
<h3>SGD<a class="headerlink" href="#sgd" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.sgd.SGD">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.sgd.</span></span><span class="sig-name descname"><span class="pre">SGD</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nesterov</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.sgd.SGD" title="Link to this definition">¶</a></dt>
<dd><p>随机梯度下降优化器。</p>
<p>参考:<a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">https://en.wikipedia.org/wiki/Stochastic_gradient_descent</a>。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\param\_new=param-lr*g\\\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – 需要优化的模型参数。</p></li>
<li><p><strong>lr</strong> – 学习率(默认值:0.01)。</p></li>
<li><p><strong>momentum</strong> – 动量因子(默认值:0)。</p></li>
<li><p><strong>nesterov</strong> – 启用 Nesterov 动量 (默认: False)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 SGD 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">sgd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">param</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="p">]</span>
<span class="n">opti</span> <span class="o">=</span> <span class="n">sgd</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">opti</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9900000, 1.9800000, 2.9700000],</span>
<span class="c1">#  [3.9600000, 4.9499998, 5.9400001, 6.9299998],</span>
<span class="c1">#  [7.9200001, 8.9099998, 9.8999996, 10.8900003]],</span>
<span class="c1"># [[11.8800001, 12.8699999, 13.8599997, 14.8500004],</span>
<span class="c1">#  [15.8400002, 16.8299999, 17.8199997, 18.8099995],</span>
<span class="c1">#  [19.7999992, 20.7900009, 21.7800007, 22.7700005]]]</span>
<span class="c1"># ]</span>

<span class="c1"># [</span>
<span class="c1"># [[[0., 0.9800000, 1.9600000, 2.9400001],</span>
<span class="c1">#  [3.9200001, 4.8999996, 5.8800001, 6.8599997],</span>
<span class="c1">#  [7.8400002, 8.8199997, 9.7999992, 10.7800007]],</span>
<span class="c1"># [[11.7600002, 12.7399998, 13.7199993, 14.7000008],</span>
<span class="c1">#  [15.6800003, 16.6599998, 17.6399994, 18.6199989],</span>
<span class="c1">#  [19.5999985, 20.5800018, 21.5600014, 22.5400009]]]</span>
<span class="c1"># ]</span>
</pre></div>
</div>
</dd></dl>

<section id="rotosolve">
<h4>Rotosolve<a class="headerlink" href="#rotosolve" title="Link to this heading">¶</a></h4>
<p>Rotosolve算法它允许相对于其他参数的固定值直接跳转到单个参数的最佳值,直接找到量子线路最佳参数的优化算法。</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.optim.rotosolve.Rotosolve">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.optim.rotosolve.</span></span><span class="sig-name descname"><span class="pre">Rotosolve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.optim.rotosolve.Rotosolve" title="Link to this definition">¶</a></dt>
<dd><p>Rotosolve:可以使用 rotosolve 算法来最小化线性组合的量子测量期望值。 请参阅以下论文:</p>
<p><a class="reference external" href="https://arxiv.org/abs/1903.12166">https://arxiv.org/abs/1903.12166</a>, Ken M. Nakanishi。</p>
<p><a class="reference external" href="https://arxiv.org/abs/1905.09692">https://arxiv.org/abs/1905.09692</a>, Mateusz Ostaszewski。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_iter</strong> – rotosolve 更新的最大迭代次数。</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>一个 Rotosolve 优化器。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.optim.rotosolve</span><span class="w"> </span><span class="kn">import</span> <span class="n">Rotosolve</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyqpanda</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">QTensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">kfloat64</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.qnn.measure</span><span class="w"> </span><span class="kn">import</span> <span class="n">expval</span>
<span class="n">machine</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">CPUQVM</span><span class="p">()</span>
<span class="n">machine</span><span class="o">.</span><span class="n">init_qvm</span><span class="p">()</span>
<span class="n">nqbits</span> <span class="o">=</span> <span class="n">machine</span><span class="o">.</span><span class="n">qAlloc_many</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">gen</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">generators</span><span class="p">,</span> <span class="n">qbits</span><span class="p">,</span> <span class="n">circuit</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">generators</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span>
        <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">qbits</span><span class="p">,</span> <span class="n">param</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">generators</span> <span class="o">==</span> <span class="s2">&quot;Y&quot;</span><span class="p">:</span>
        <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">qbits</span><span class="p">,</span> <span class="n">param</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="n">qbits</span><span class="p">,</span> <span class="n">param</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">circuits</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">generators</span><span class="p">,</span> <span class="n">circuit</span><span class="p">):</span>
    <span class="n">gen</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">generators</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nqbits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">circuit</span><span class="p">)</span>
    <span class="n">gen</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">generators</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nqbits</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">circuit</span><span class="p">)</span>
    <span class="n">circuit</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">CNOT</span><span class="p">(</span><span class="n">nqbits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nqbits</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">prog</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">QProg</span><span class="p">()</span>
    <span class="n">prog</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">circuit</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prog</span>


<span class="k">def</span><span class="w"> </span><span class="nf">ansatz1</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="n">QTensor</span><span class="p">,</span> <span class="n">generators</span><span class="p">):</span>
    <span class="n">circuit</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">QCircuit</span><span class="p">()</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">getdata</span><span class="p">()</span>
    <span class="n">prog</span> <span class="o">=</span> <span class="n">circuits</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">generators</span><span class="p">,</span> <span class="n">circuit</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expval</span><span class="p">(</span><span class="n">machine</span><span class="p">,</span> <span class="n">prog</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;Z0&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
                <span class="n">nqbits</span><span class="p">),</span> <span class="n">expval</span><span class="p">(</span><span class="n">machine</span><span class="p">,</span> <span class="n">prog</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;Y1&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">nqbits</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">ansatz2</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="n">QTensor</span><span class="p">,</span> <span class="n">generators</span><span class="p">):</span>
    <span class="n">circuit</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">QCircuit</span><span class="p">()</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">getdata</span><span class="p">()</span>
    <span class="n">prog</span> <span class="o">=</span> <span class="n">circuits</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">generators</span><span class="p">,</span> <span class="n">circuit</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expval</span><span class="p">(</span><span class="n">machine</span><span class="p">,</span> <span class="n">prog</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;X0&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">nqbits</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">Z</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">ansatz1</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">ansatz2</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;Y&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">Y</span> <span class="o">+</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">Z</span> <span class="o">-</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">X</span>


<span class="n">t</span> <span class="o">=</span> <span class="n">QTensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">kfloat64</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">Rotosolve</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">costs_rotosolve</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">costs_rotosolve</span><span class="p">)</span>
<span class="c1">#[0.7642691884821847, -0.799999999999997, -0.799999999999997, -0.799999999999997, -0.799999999999997]</span>
</pre></div>
</div>
</dd></dl>

<figure class="align-default">
<img alt="../_images/rotosolve.png" src="../_images/rotosolve.png" />
</figure>
</section>
</section>
</section>
<section id="id11">
<h2>指标模块<a class="headerlink" href="#id11" title="Link to this heading">¶</a></h2>
<section id="mse">
<h3>MSE<a class="headerlink" href="#mse" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.MSE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">MSE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.MSE" title="Link to this definition">¶</a></dt>
<dd><p>计算均方误差 (Mean Squared Error, MSE)。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,估计目标值。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>输出float结果。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">MSE</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># 9.0</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">MSE</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># 9.0</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="rmse">
<h3>RMSE<a class="headerlink" href="#rmse" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.RMSE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">RMSE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.RMSE" title="Link to this definition">¶</a></dt>
<dd><p>计算均方根误差 (Root Mean Square Error, RMSE) 。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,估计目标值。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>输出float结果。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">RMSE</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># 3.0</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">RMSE</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># 3.0</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="mae">
<h3>MAE<a class="headerlink" href="#mae" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.MAE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">MAE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.MAE" title="Link to this definition">¶</a></dt>
<dd><p>计算预测值和真实值之间绝对平均误差 (Mean Absolute Error , MAE) 。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,估计目标值。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>输出float结果。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">MAE</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># 3.0</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">MAE</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1"># 3.0</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="r-square">
<h3>R_Square<a class="headerlink" href="#r-square" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.R_Square">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">R_Square</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.R_Square" title="Link to this definition">¶</a></dt>
<dd><p>计算预测值和真实值之间的R方分数。
可能的最佳分数为1.0,可以为负(因为模型可以任意恶化)。不考虑输入特征的常数模型,将获得0.0的R^2分数。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 形状类似(n_samples,)或(n_samples, n_outputs)的输入,估计目标值。</p></li>
<li><p><strong>sample_weight</strong> – 形状类似(n_samples,)的数组,可选样本权重,默认为None。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>输出float结果。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">R_Square</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="c1"># 0.09999999999999998</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">R_Square</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="c1"># 0.15625</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="precision-recall-f1-2-score">
<h3>precision_recall_f1_2_score<a class="headerlink" href="#precision-recall-f1-2-score" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_2_score">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">precision_recall_f1_2_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_2_score" title="Link to this definition">¶</a></dt>
<dd><p>计算2分类任务下预测值的精确率,召回率和F1分数。其中预测值和真值需要是形状类似(n_samples,)的QTensor,值为0或1,代表两个类的标签。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 一维QTensor的输入,形状类似(n_samples,),真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 一维QTensor的输入,形状类似(n_samples,),估计目标值。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>precision - 精确率</p></li>
<li><p>recall - 召回率</p></li>
<li><p>f1 - F1 分数</p></li>
</ul>
</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_2_score</span><span class="p">(</span>
    <span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
<span class="c1"># 0.5 0.6 0.5454545454545454</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="precision-recall-f1-n-score">
<h3>precision_recall_f1_N_score<a class="headerlink" href="#precision-recall-f1-n-score" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_N_score">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">precision_recall_f1_N_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_N_score" title="Link to this definition">¶</a></dt>
<dd><p>多分类任务的精确率,召回率,F1分数计算。其中预测值和真值是形状类似(n_samples,)的QTensor,值为0到N-1的整数,代表N个类的标签。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 一维QTensor的输入,真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 一维QTensor的输入,估计目标值。</p></li>
<li><p><strong>N</strong> – N类(类别数)。</p></li>
<li><p><strong>average</strong> – <p>string, [‘micro’, ‘macro’, ‘weighted’]。
多类/多标签目标需要此参数。
<code class="docutils literal notranslate"><span class="pre">'micro'</span></code>: 通过计算总真正数来全局计算指标,假阴性和假阳性。</p>
<p><code class="docutils literal notranslate"><span class="pre">'macro'</span></code>: 计算每个标签的指标,并找到其未加权值。意思是不考虑标签的平衡。</p>
<p><code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>: 计算每个标签的指标,并找到它们的平均值(每个标签的真实实例数)。这改变 <code class="docutils literal notranslate"><span class="pre">'macro'</span></code> 以解释标签不平衡; 这可能会导致F分数不在精度和召回之间。</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>precision - 精确率</p></li>
<li><p>recall - 召回率</p></li>
<li><p>f1 - F1 分数</p></li>
</ul>
</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">reference_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">prediciton_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">reference_list</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">prediciton_list</span><span class="p">)</span>

<span class="n">precision_micro</span><span class="p">,</span> <span class="n">recall_micro</span><span class="p">,</span> <span class="n">f1_micro</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_N_score</span><span class="p">(</span>
    <span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_micro</span><span class="p">,</span> <span class="n">recall_micro</span><span class="p">,</span> <span class="n">f1_micro</span><span class="p">)</span>
<span class="c1"># 0.6 0.6 0.6</span>

<span class="n">precision_macro</span><span class="p">,</span> <span class="n">recall_macro</span><span class="p">,</span> <span class="n">f1_macro</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_N_score</span><span class="p">(</span>
    <span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_macro</span><span class="p">,</span> <span class="n">recall_macro</span><span class="p">,</span> <span class="n">f1_macro</span><span class="p">)</span>
<span class="c1"># 0.5833333333333334 0.5888888888888889 0.5793650793650794</span>

<span class="n">precision_weighted</span><span class="p">,</span> <span class="n">recall_weighted</span><span class="p">,</span> <span class="n">f1_weighted</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_N_score</span><span class="p">(</span>
    <span class="n">y_true_Qtensor</span><span class="p">,</span> <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_weighted</span><span class="p">,</span> <span class="n">recall_weighted</span><span class="p">,</span> <span class="n">f1_weighted</span><span class="p">)</span>
<span class="c1"># 0.625 0.6 0.6047619047619047</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="precision-recall-f1-multi-score">
<h3>precision_recall_f1_Multi_score<a class="headerlink" href="#precision-recall-f1-multi-score" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_Multi_score">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">precision_recall_f1_Multi_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.precision_recall_f1_Multi_score" title="Link to this definition">¶</a></dt>
<dd><p>多分类任务的精确率,召回率,F1分数计算。其中预测值和真值是形状类似(n_samples,N)的QTensor,预测值和真实标签必须为0-1独热编码的形式。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 二维QTensor的输入,真实目标值。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 二维QTensor的输入,估计目标值。</p></li>
<li><p><strong>N</strong> – N类(类别数)。</p></li>
<li><p><strong>average</strong> – <p>string, [‘micro’, ‘macro’, ‘weighted’]。
多类/多标签目标需要此参数。
<code class="docutils literal notranslate"><span class="pre">'micro'</span></code>: 通过计算总真正数来全局计算指标,假阴性和假阳性。</p>
<p><code class="docutils literal notranslate"><span class="pre">'macro'</span></code>: 计算每个标签的指标,并找到其未加权值。意思是不考虑标签的平衡。</p>
<p><code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>: 计算每个标签的指标,并找到它们的平均值(每个标签的真实实例数)。这改变 <code class="docutils literal notranslate"><span class="pre">'macro'</span></code> 以解释标签不平衡; 这可能会导致F分数不在精度和召回之间。</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>precision - 精确率</p></li>
<li><p>recall - 召回率</p></li>
<li><p>f1 - F1 分数</p></li>
</ul>
</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">reference_list</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="n">prediciton_list</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">reference_list</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">prediciton_list</span><span class="p">)</span>

<span class="n">micro_precision</span><span class="p">,</span> <span class="n">micro_recall</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_Multi_score</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span>
            <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">micro_precision</span><span class="p">,</span> <span class="n">micro_recall</span><span class="p">,</span> <span class="n">micro_f1</span><span class="p">)</span> <span class="c1"># 0.5 0.2 0.28571428571428575</span>

<span class="n">macro_precision</span><span class="p">,</span> <span class="n">macro_recall</span><span class="p">,</span> <span class="n">macro_f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_Multi_score</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span>
            <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">macro_precision</span><span class="p">,</span> <span class="n">macro_recall</span><span class="p">,</span> <span class="n">macro_f1</span><span class="p">)</span> <span class="c1"># 0.25 0.16666666666666666 0.2</span>

<span class="n">weighted_precision</span><span class="p">,</span> <span class="n">weighted_recall</span><span class="p">,</span> <span class="n">weighted_f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_Multi_score</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span>
            <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">weighted_precision</span><span class="p">,</span> <span class="n">weighted_recall</span><span class="p">,</span> <span class="n">weighted_f1</span><span class="p">)</span> <span class="c1"># 0.3 0.19999999999999998 0.24</span>

<span class="n">reference_list</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">prediciton_list</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">y_true_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">reference_list</span><span class="p">)</span>
<span class="n">y_pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">prediciton_list</span><span class="p">)</span>

<span class="n">micro_precision</span><span class="p">,</span> <span class="n">micro_recall</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_Multi_score</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span>
            <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">micro_precision</span><span class="p">,</span> <span class="n">micro_recall</span><span class="p">,</span> <span class="n">micro_f1</span><span class="p">)</span> <span class="c1"># 0.5 0.5714285714285714 0.5333333333333333</span>

<span class="n">macro_precision</span><span class="p">,</span> <span class="n">macro_recall</span><span class="p">,</span> <span class="n">macro_f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_Multi_score</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span>
            <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">macro_precision</span><span class="p">,</span> <span class="n">macro_recall</span><span class="p">,</span> <span class="n">macro_f1</span><span class="p">)</span> <span class="c1"># 0.5 0.5555555555555555 0.5238095238095238</span>

<span class="n">weighted_precision</span><span class="p">,</span> <span class="n">weighted_recall</span><span class="p">,</span> <span class="n">weighted_f1</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">precision_recall_f1_Multi_score</span><span class="p">(</span><span class="n">y_true_Qtensor</span><span class="p">,</span>
            <span class="n">y_pred_Qtensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">weighted_precision</span><span class="p">,</span> <span class="n">weighted_recall</span><span class="p">,</span> <span class="n">weighted_f1</span><span class="p">)</span> <span class="c1"># 0.5 0.5714285714285714 0.5306122448979592</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="auc-calculate">
<h3>auc_calculate<a class="headerlink" href="#auc-calculate" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.utils.metrics.auc_calculate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.utils.metrics.</span></span><span class="sig-name descname"><span class="pre">auc_calculate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred_Qtensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_intermediate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.utils.metrics.auc_calculate" title="Link to this definition">¶</a></dt>
<dd><p>计算模型对预测值和真值之间进行分类获取的(Area Under Curve, AUC)结果。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true_Qtensor</strong> – 一维QTensor的输入,shape = [n_samples]。
真正的二进制标签。如果标签不是{1,1}或{0,1},则pos_label应明确给出。</p></li>
<li><p><strong>y_pred_Qtensor</strong> – 一维QTensor的输入,shape = [n_samples]。
目标分数,可以是正的概率估计类别、置信值或决策的非阈值度量(由某些分类器上的“决策函数”返回)</p></li>
<li><p><strong>pos_label</strong> – int 或 str,正类的标签。默认为None。
当 <code class="docutils literal notranslate"><span class="pre">pos_label</span></code> 是 None 时,如果 <code class="docutils literal notranslate"><span class="pre">y_true_Qtensor</span></code> 位于{-1,1}或{0,1}, <code class="docutils literal notranslate"><span class="pre">pos_label</span></code> 设置为1,否则将引发错误。</p></li>
<li><p><strong>sample_weight</strong> – 形状(n_samples,)的数组,默认为None。</p></li>
<li><p><strong>drop_intermediate</strong> – boolean,是否降低一些在绘制的ROC曲线上不会出现的次优阈值。(默认为None)。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>输出float结果。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">vqnet_metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">_core</span>
<span class="n">_vqnet</span> <span class="o">=</span> <span class="n">_core</span><span class="o">.</span><span class="n">vqnet</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">y_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">auc_calculate</span><span class="p">(</span><span class="n">y_Qtensor</span><span class="p">,</span> <span class="n">pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;auc:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span> <span class="c1"># 0.92</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">auc_calculate</span><span class="p">(</span><span class="n">y_Qtensor</span><span class="p">,</span> <span class="n">pred_Qtensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;auc:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span> <span class="c1"># 0.625</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">pred_Qtensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">vqnet_metrics</span><span class="o">.</span><span class="n">auc_calculate</span><span class="p">(</span><span class="n">y_Qtensor</span><span class="p">,</span> <span class="n">pred_Qtensor</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;auc:&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span> <span class="c1"># 0.1111111111111111</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="vqnet">
<span id="vqnet-dist"></span><h2>VQNet原生分布式计算模块<a class="headerlink" href="#vqnet" title="Link to this heading">¶</a></h2>
<p>该模块使用mpi启动多进程并行计算, 使用nccl进行GPU之间通信。仅在linux操作系统下能够使用。</p>
<section id="id12">
<h3>环境部署<a class="headerlink" href="#id12" title="Link to this heading">¶</a></h3>
<p>以下介绍VQNet分别基于CPU、GPU分布式计算所需的Linux系统下环境的部署.该部分必须MPI的支持, 以下介绍MPI的环境部署。</p>
<section id="mpi">
<h4>MPI安装<a class="headerlink" href="#mpi" title="Link to this heading">¶</a></h4>
<p>MPI为CPU间通信的常用库, <strong>VQNet中CPU的分布式计算功能则基于MPI进行实现</strong>,以下将介绍如何在Linux系统中对MPI进行安装(目前基于CPU的分布式计算功能仅在Linux上实现)。</p>
<p>检测gcc、gfortran编译器是否安装。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">which</span> <span class="n">gcc</span>
<span class="n">which</span> <span class="n">gfortran</span>
</pre></div>
</div>
<p>当显示了gcc和gfortran的路径,即可进行下一步的安装,若没有相应的编译器,请先安装编译器。当检查完编译器之后,使用wget命令下载。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">mpich</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">static</span><span class="o">/</span><span class="n">downloads</span><span class="o">/</span><span class="mf">3.3.2</span><span class="o">/</span><span class="n">mpich</span><span class="o">-</span><span class="mf">3.3.2</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">tar</span> <span class="o">-</span><span class="n">zxvf</span> <span class="n">mpich</span><span class="o">-</span><span class="mf">3.3.2</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
<span class="n">cd</span> <span class="n">mpich</span><span class="o">-</span><span class="mf">3.3.2</span>
<span class="o">./</span><span class="n">configure</span> <span class="o">--</span><span class="n">prefix</span><span class="o">=/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">mpich</span>
<span class="n">make</span>
<span class="n">make</span> <span class="n">install</span>
</pre></div>
</div>
<p>完成mpich的编译安装,配置其环境变量</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vim</span> <span class="o">~/.</span><span class="n">bashrc</span>

<span class="c1"># 在文档最下面加入</span>
<span class="n">export</span> <span class="n">PATH</span><span class="o">=</span><span class="s2">&quot;/usr/local/mpich/bin:$PATH&quot;</span>
</pre></div>
</div>
<p>保存退出之后 使用source执行</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">source</span> <span class="o">~/.</span><span class="n">bashrc</span>
</pre></div>
</div>
<p>用which来检验下配置的环境变量是否正确。显示了其路径, 则说明安装顺利完成。</p>
<p>此外我们还必须安装 <strong>mpi4py</strong> 库。通过pip install完成mpi4py的安装即可, 若是出现以下类似错误</p>
<img alt="../_images/mpi_bug.png" class="align-center" src="../_images/mpi_bug.png" />
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>为mpi4py与python版本之间不兼容的问题, 可以通过以下方法解决</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># 通过下列代码暂存当前python环境的编译器
pushd /root/anaconda3/envs/$CONDA_DEFAULT_ENV/compiler_compat &amp;&amp; mv ld ld.bak &amp;&amp; popd

# 再次安装
pip install mpi4py

# 还原
pushd /root/anaconda3/envs/$CONDA_DEFAULT_ENV/compiler_compat &amp;&amp; mv ld.bak ld &amp;&amp; popd
</pre></div>
</div>
</section>
<section id="nccl">
<h4>NCCL安装<a class="headerlink" href="#nccl" title="Link to this heading">¶</a></h4>
<p>NCCL为GPU间通信的常用库, <strong>VQNet中GPU的分布式计算功能则基于NCCL进行实现</strong>,本软件默认在安装时候同时安装NCCL的动态链接库, 一般不需要安装NCCL。
如果要安装NCCL,可以按照以下介绍如何在Linux系统中对NCCL进行安装(目前基于GPU的分布式计算功能仅在Linux上实现).</p>
<p>从github上将NCCL的仓库拉到本地:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">NVIDIA</span><span class="o">/</span><span class="n">nccl</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
<p>进入nccl根目录并编译</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">nccl</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j</span> <span class="n">src</span><span class="o">.</span><span class="n">build</span>
</pre></div>
</div>
<p>如果cuda没有安装到默认的路径即/usr/local/cuda, 则需要定义CUDA的路径, 使用以下代码来编译</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">src</span><span class="o">.</span><span class="n">build</span> <span class="n">CUDA_HOME</span><span class="o">=&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">cuda</span> <span class="n">install</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>并且可以根据BUILDDIR指定安装目录, 指令如下</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">src</span><span class="o">.</span><span class="n">build</span> <span class="n">CUDA_HOME</span><span class="o">=&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">cuda</span> <span class="n">install</span><span class="o">&gt;</span> <span class="n">BUILDDIR</span><span class="o">=/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">nccl</span>
</pre></div>
</div>
<p>安装完成后在.bashrc文件中添加配置</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vim ~/.bashrc

# 在最下面加入
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/nccl/lib
export PATH=$PATH:/usr/local/nccl/bin
</pre></div>
</div>
<p>保存后, 执行</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">source</span> <span class="o">~/.</span><span class="n">bashrc</span>
</pre></div>
</div>
<p>可以通过nccl-test进行验证</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">NVIDIA</span><span class="o">/</span><span class="n">nccl</span><span class="o">-</span><span class="n">tests</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">nccl</span><span class="o">-</span><span class="n">tests</span>
<span class="n">make</span> <span class="o">-</span><span class="n">j12</span> <span class="n">CUDA_HOME</span><span class="o">=/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span>
<span class="o">./</span><span class="n">build</span><span class="o">/</span><span class="n">all_reduce_perf</span> <span class="o">-</span><span class="n">b</span> <span class="mi">8</span> <span class="o">-</span><span class="n">e</span> <span class="mi">256</span><span class="n">M</span> <span class="o">-</span><span class="n">f</span> <span class="mi">2</span> <span class="o">-</span><span class="n">g</span> <span class="mi">1</span>
</pre></div>
</div>
</section>
<section id="id13">
<h4>节点间通信环境部署<a class="headerlink" href="#id13" title="Link to this heading">¶</a></h4>
<p>在多节点上实现分布式计算,首先 <strong>需要保证多节点上mpich环境的一致,python环境一致</strong> ,其次,需要设置 <strong>节点间的免密通信</strong> 。</p>
<p>假设需要设置node0(主节点)、node1、node2三个节点的免密通信。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 在每个节点上执行</span>
<span class="n">ssh</span><span class="o">-</span><span class="n">keygen</span>

<span class="c1"># 之后一直回车,在.ssh文件夹下生成一个公钥(id_rsa.pub)一个私钥(id_rsa)</span>
<span class="c1"># 将其另外两个节点的公钥都添加到第一个节点的authorized_keys文件中,</span>
<span class="c1"># 再将第一个节点authorized_keys文件传到另外两个节点便可以实现节点间的免密通信</span>
<span class="c1"># 在子节点node1上执行</span>
<span class="n">cat</span> <span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">id_dsa</span><span class="o">.</span><span class="n">pub</span> <span class="o">&gt;&gt;</span> <span class="n">node0</span><span class="p">:</span><span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>

<span class="c1"># 在子节点node2上执行</span>
<span class="n">cat</span> <span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">id_dsa</span><span class="o">.</span><span class="n">pub</span> <span class="o">&gt;&gt;</span> <span class="n">node0</span><span class="p">:</span><span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>

<span class="c1"># 先删除node1、node2中的authorized_keys文件后,在node0上将authorized_keys文件拷贝到另外两个节点上</span>
<span class="n">scp</span> <span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>  <span class="n">node1</span><span class="p">:</span><span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>
<span class="n">scp</span> <span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>  <span class="n">node2</span><span class="p">:</span><span class="o">~/.</span><span class="n">ssh</span><span class="o">/</span><span class="n">authorized_keys</span>

<span class="c1"># 保证三个不同节点生成的公钥都在authorized_keys文件中,即可实现节点间的免密通信</span>
</pre></div>
</div>
<p>可选的, 最好还设置一个共享目录,使得改变共享目录下的文件时,不同节点中文件也会进行更改,预防多节点运行模型时不同节点中的文件不同步的问题。
使用nfs-utils和rpcbind实现共享目录。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 安装软件包</span>
<span class="n">yum</span> <span class="o">-</span><span class="n">y</span> <span class="n">install</span> <span class="n">nfs</span><span class="o">*</span> <span class="n">rpcbind</span>

<span class="c1"># 编辑主节点上配置文件</span>
<span class="n">vim</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">exports</span>
<span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">mpi</span> <span class="o">*</span><span class="p">(</span><span class="n">rw</span><span class="p">,</span><span class="n">sync</span><span class="p">,</span><span class="n">no_all_squash</span><span class="p">,</span><span class="n">no_subtree_check</span><span class="p">)</span>

<span class="c1"># 主节点上启动服务</span>
<span class="n">systemctl</span> <span class="n">start</span> <span class="n">rpcbind</span>
<span class="n">systemctl</span> <span class="n">start</span> <span class="n">nfs</span>

<span class="c1"># 在所有子结点node1,node2上mount要共享的目录</span>
<span class="n">mount</span> <span class="n">node1</span><span class="p">:</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">mpi</span><span class="o">/</span> <span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">mpi</span>
<span class="n">mount</span> <span class="n">node2</span><span class="p">:</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">mpi</span><span class="o">/</span> <span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">mpi</span>
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h3>分布式启动<a class="headerlink" href="#id14" title="Link to this heading">¶</a></h3>
<p>使用分布式计算接口,通过 <code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 命令启动, 接下来介绍 <code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 的各个参数.</p>
<section id="n-np">
<h4>n, np<a class="headerlink" href="#n-np" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过 <code class="docutils literal notranslate"><span class="pre">-n</span></code>, <code class="docutils literal notranslate"><span class="pre">-np</span></code> 参数控制启动的进程数,执行样例如下:</p>
<blockquote>
<div><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span> <span class="c1"># init mpi controller</span>

<span class="n">rank</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -n 2 python test.py</span>
<span class="c1"># vqnetrun -np 2 python test.py</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="h-hosts">
<h4>H, hosts<a class="headerlink" href="#h-hosts" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过 <code class="docutils literal notranslate"><span class="pre">-H</span></code>, <code class="docutils literal notranslate"><span class="pre">--hosts</span></code> 指定节点以及进程分配来跨节点执行(在跨节点运行时必须将节点的环境配置成功, 在相同的环境,相同的路径下执行),执行样例如下:</p>
<blockquote>
<div><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span> <span class="n">get_host_name</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span> <span class="c1"># init mpi controller</span>

<span class="n">rank</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LocalRank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getLocalRank</span><span class="p">()</span><span class="si">}</span><span class="s2"> hosts name </span><span class="si">{</span><span class="n">get_host_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -np 4 -H node0:1,node2:1 python test.py</span>
<span class="c1"># vqnetrun -np 4 --hosts node0:1,node2:1 python test.py</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="hostfile-f-hostfile">
<span id="hostfile"></span><h4>hostfile, f, hostfile<a class="headerlink" href="#hostfile-f-hostfile" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过指定hosts文件来指定节点以及进程分配来跨节点(在跨节点运行时必须将节点的环境配置成功, 在相同的环境,相同的路径下执行), 命令行参数为 <code class="docutils literal notranslate"><span class="pre">-hostfile</span></code>, <code class="docutils literal notranslate"><span class="pre">-f</span></code>, <code class="docutils literal notranslate"><span class="pre">--hostfile</span></code>.</p>
<p>文件内每行的格式必须为:&lt;hostname&gt; slots=&lt;slots&gt; 如；</p>
<p>node0 slots=1</p>
<p>node2 slots=1</p>
<p>执行样例如下</p>
<blockquote>
<div><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span> <span class="n">get_host_name</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span> <span class="c1"># init mpi controller</span>

<span class="n">rank</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LocalRank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getLocalRank</span><span class="p">()</span><span class="si">}</span><span class="s2"> hosts name </span><span class="si">{</span><span class="n">get_host_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -np 4 -f hosts python test.py</span>
<span class="c1"># vqnetrun -np 4 -hostfile hosts python test.py</span>
<span class="c1"># vqnetrun -np 4 --hostfile hosts python test.py</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="output-filename">
<h4>output-filename<a class="headerlink" href="#output-filename" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过命令行参数 <code class="docutils literal notranslate"><span class="pre">--output-filename</span></code> 来将输出结果保存到指定文件.</p>
<p>执行样例如下</p>
<blockquote>
<div><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span> <span class="n">get_host_name</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span> <span class="c1"># init mpi controller</span>

<span class="n">rank</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LocalRank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getLocalRank</span><span class="p">()</span><span class="si">}</span><span class="s2"> hosts name </span><span class="si">{</span><span class="n">get_host_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -np 4 --hostfile hosts --output-filename output  python test.py</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="verbose">
<h4>verbose<a class="headerlink" href="#verbose" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过命令行参数 <code class="docutils literal notranslate"><span class="pre">--verbose</span></code> 来对节点间的通信进行检测,并额外输出检测结果。</p>
<p>执行样例如下</p>
<blockquote>
<div><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span> <span class="n">get_host_name</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span> <span class="c1"># init mpi controller</span>

<span class="n">rank</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LocalRank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getLocalRank</span><span class="p">()</span><span class="si">}</span><span class="s2"> hosts name </span><span class="si">{</span><span class="n">get_host_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -np 4 --hostfile hosts --verbose python test.py</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="start-timeout">
<h4>start-timeout<a class="headerlink" href="#start-timeout" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过命令行参数 <code class="docutils literal notranslate"><span class="pre">--start-timeout</span></code> 来指定超时前执行所有检查并启动进程。默认值为 30 秒。</p>
<p>执行样例如下</p>
<blockquote>
<div><p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span> <span class="n">get_host_name</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span> <span class="c1"># init mpi controller</span>

<span class="n">rank</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LocalRank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getLocalRank</span><span class="p">()</span><span class="si">}</span><span class="s2"> hosts name </span><span class="si">{</span><span class="n">get_host_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -np 4 --start-timeout 10 python test.py</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="h">
<h4>h<a class="headerlink" href="#h" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">vqnetrun</span></code> 接口中可以通过该标志, 输出vqnetrun支持的所有参数以及参数的详细介绍。</p>
<p>执行代码如下</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># vqnetrun -h</span>
</pre></div>
</div>
</div></blockquote>
</section>
</section>
<section id="commcontroller">
<h3>CommController<a class="headerlink" href="#commcontroller" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.ControllComm.</span></span><span class="sig-name descname"><span class="pre">CommController</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backend</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">world_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController" title="Link to this definition">¶</a></dt>
<dd><p>CommController用于控制在cpu、gpu下数据通信的控制器, 通过设置参数 <cite>backend</cite> 来生成cpu(mpi)、gpu(nccl)的控制器。(目前分布式计算的功能仅支持linux操作系系统下使用)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>backend</strong> – 用于生成cpu或者gpu的数据通信控制器。</p></li>
<li><p><strong>rank</strong> – 该参数仅在非pyvqnet后端下有用, 默认值为: None。</p></li>
<li><p><strong>world_size</strong> – 该参数仅在非pyvqnet后端下有用, 默认值为: None。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>CommController 实例。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span> <span class="c1"># init nccl controller</span>

<span class="c1"># Comm_OP = CommController(&quot;mpi&quot;) # init mpi controller</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.getRank">
<span class="sig-name descname"><span class="pre">getRank</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.getRank" title="Link to this definition">¶</a></dt>
<dd><p>用于获得当前进程的进程号。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>返回当前进程的进程号。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span> <span class="c1"># init nccl controller</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.getSize">
<span class="sig-name descname"><span class="pre">getSize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.getSize" title="Link to this definition">¶</a></dt>
<dd><p>用于获得总共启动的进程数。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>返回总共进程的数量。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span> <span class="c1"># init nccl controller</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">getSize</span><span class="p">()</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
<span class="c1"># 2</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.getLocalRank">
<span class="sig-name descname"><span class="pre">getLocalRank</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.getLocalRank" title="Link to this definition">¶</a></dt>
<dd><p>用于获得当前机器上的当前进程号。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>当前机器上的当前进程号。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span> <span class="c1"># init nccl controller</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">getLocalRank</span><span class="p">()</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.ncclSplitGroup">
<span class="sig-name descname"><span class="pre">ncclSplitGroup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rankL</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.ncclSplitGroup" title="Link to this definition">¶</a></dt>
<dd><p>用于划分gpu上的通信组。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>rankL</strong> – 进程组列表。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">ncclSplitGroup</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.barrier">
<span class="sig-name descname"><span class="pre">barrier</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.barrier" title="Link to this definition">¶</a></dt>
<dd><p>同步。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>同步操作。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.GetDeviceNum">
<span class="sig-name descname"><span class="pre">GetDeviceNum</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.GetDeviceNum" title="Link to this definition">¶</a></dt>
<dd><p>用于获得当前节点上的显卡数量, (仅支持gpu下使用)。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>返回当前节点上显卡数量。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">GetDeviceNum</span><span class="p">()</span>
<span class="c1"># python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allreduce">
<span class="sig-name descname"><span class="pre">allreduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_op</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'avg'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allreduce" title="Link to this definition">¶</a></dt>
<dd><p>支持对数据作allreduce通信。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>c_op</strong> – 计算方式.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">allreduce</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.reduce">
<span class="sig-name descname"><span class="pre">reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_op</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'avg'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.reduce" title="Link to this definition">¶</a></dt>
<dd><p>支持对数据作reduce通信。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据。</p></li>
<li><p><strong>root</strong> – 指定数据返回的节点。</p></li>
<li><p><strong>c_op</strong> – 计算方式。</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.broadcast">
<span class="sig-name descname"><span class="pre">broadcast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.broadcast" title="Link to this definition">¶</a></dt>
<dd><p>将指定进程root上的数据广播到所有进程上。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据。</p></li>
<li><p><strong>root</strong> – 指定的节点。</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allgather">
<span class="sig-name descname"><span class="pre">allgather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allgather" title="Link to this definition">¶</a></dt>
<dd><p>将所有进程上数据allgather到一起。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> – 输入数据。</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">allgather</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.send">
<span class="sig-name descname"><span class="pre">send</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.send" title="Link to this definition">¶</a></dt>
<dd><p>p2p通信接口。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>dest</strong> – 目的进程.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">recv</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

<span class="k">if</span> <span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">Comm_OP</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">Comm_OP</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">recv</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">recv</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.recv">
<span class="sig-name descname"><span class="pre">recv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.recv" title="Link to this definition">¶</a></dt>
<dd><p>p2p通信接口。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>source</strong> – 接受进程.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>

<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">recv</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

<span class="k">if</span> <span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">Comm_OP</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">Comm_OP</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">recv</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">recv</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allreduce_group">
<span class="sig-name descname"><span class="pre">allreduce_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_op</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'avg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">GroupComm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allreduce_group" title="Link to this definition">¶</a></dt>
<dd><p>组内allreduce通信接口。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>c_op</strong> – 计算方法.</p></li>
<li><p><strong>GroupComm</strong> – 通信组, 仅mpi进行组内通信时需要.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span><span class="p">,</span><span class="n">get_local_rank</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">ncclSplitGroup</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">complex_data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">get_rank</span><span class="p">()],</span><span class="n">dtype</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">(</span><span class="mi">1000</span><span class="o">+</span> <span class="n">get_local_rank</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;allreduce_group before rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">allreduce_group</span><span class="p">(</span><span class="n">complex_data</span><span class="p">,</span> <span class="n">c_op</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;allreduce_group after rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.reduce_group">
<span class="sig-name descname"><span class="pre">reduce_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_op</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'avg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">GroupComm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.reduce_group" title="Link to this definition">¶</a></dt>
<dd><p>组内reduce通信接口。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>root</strong> – 指定进程号.</p></li>
<li><p><strong>c_op</strong> – 计算方法.</p></li>
<li><p><strong>GroupComm</strong> – 通信组, 仅mpi进行组内通信时需要.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span><span class="p">,</span><span class="n">get_local_rank</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">ncclSplitGroup</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">complex_data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">get_rank</span><span class="p">()],</span><span class="n">dtype</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">(</span><span class="mi">1000</span><span class="o">+</span> <span class="n">get_local_rank</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reduce_group before rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">reduce_group</span><span class="p">(</span><span class="n">complex_data</span><span class="p">,</span> <span class="n">c_op</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reduce_group after rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.broadcast_group">
<span class="sig-name descname"><span class="pre">broadcast_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">GroupComm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.broadcast_group" title="Link to this definition">¶</a></dt>
<dd><p>组内broadcast通信接口。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>root</strong> – 指定进程号.</p></li>
<li><p><strong>GroupComm</strong> – 通信组, 仅mpi进行组内通信时需要.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span><span class="p">,</span><span class="n">get_local_rank</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">ncclSplitGroup</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">complex_data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">get_rank</span><span class="p">()],</span><span class="n">dtype</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">(</span><span class="mi">1000</span><span class="o">+</span> <span class="n">get_local_rank</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;broadcast_group before rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">broadcast_group</span><span class="p">(</span><span class="n">complex_data</span><span class="p">)</span>
<span class="n">Comm_OP</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;broadcast_group after rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allgather_group">
<span class="sig-name descname"><span class="pre">allgather_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">GroupComm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.CommController.allgather_group" title="Link to this definition">¶</a></dt>
<dd><p>组内allgather通信接口。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> – 输入数据.</p></li>
<li><p><strong>GroupComm</strong> – 通信组, 仅mpi进行组内通信时需要.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span><span class="p">,</span><span class="n">init_group</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>

<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>
<span class="n">group</span> <span class="o">=</span> <span class="n">init_group</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="c1">#mpi init group internally</span>
<span class="c1"># A list of lists, where each sublist contains a communicator and the corresponding rank list.</span>
<span class="n">complex_data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">get_rank</span><span class="p">()],</span><span class="n">dtype</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; before rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">comm_</span> <span class="ow">in</span> <span class="n">group</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span> <span class="ow">in</span> <span class="n">comm_</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">complex_data</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">all_gather_group</span><span class="p">(</span><span class="n">complex_data</span><span class="p">,</span> <span class="n">comm_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;after rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># mpirun -n 2 python test.py</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommController</span><span class="p">,</span><span class="n">get_rank</span><span class="p">,</span><span class="n">get_local_rank</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
<span class="n">Comm_OP</span><span class="o">.</span><span class="n">ncclSplitGroup</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">complex_data</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">([</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">get_rank</span><span class="p">()],</span><span class="n">dtype</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">toGPU</span><span class="p">(</span><span class="mi">1000</span><span class="o">+</span> <span class="n">get_local_rank</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; before rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">complex_data</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">all_gather_group</span><span class="p">(</span><span class="n">complex_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;after rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">complex_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># mpirun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="split-data">
<h3>split_data<a class="headerlink" href="#split-data" title="Link to this heading">¶</a></h3>
<p>在多进程中,使用 <code class="docutils literal notranslate"><span class="pre">split_data</span></code> 根据进程数对数据进行切分,返回相应进程上数据。</p>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.datasplit.split_data">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.datasplit.</span></span><span class="sig-name descname"><span class="pre">split_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.datasplit.split_data" title="Link to this definition">¶</a></dt>
<dd><p>设置分布式计算参数。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_train</strong> – <cite>np.array</cite> - 训练数据.</p></li>
<li><p><strong>y_train</strong> – <cite>np.array</cite> -  训练数据标签.</p></li>
<li><p><strong>shuffle</strong> – <cite>bool</cite> - 是否打乱后再进行切分,默认值是False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>切分后的训练数据和标签。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">split_data</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span> <span class="n">split_data</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="get-local-rank">
<h3>get_local_rank<a class="headerlink" href="#get-local-rank" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.get_local_rank">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.ControllComm.</span></span><span class="sig-name descname"><span class="pre">get_local_rank</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.get_local_rank" title="Link to this definition">¶</a></dt>
<dd><p>得到当前节点上进程号。例如你在第2个节点的第3个进程,每个节点5个进程,则返回2。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>当前机器上的当前进程号。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed.ControllComm</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_local_rank</span>

<span class="nb">print</span><span class="p">(</span><span class="n">get_local_rank</span><span class="p">())</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="get-rank">
<h3>get_rank<a class="headerlink" href="#get-rank" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.get_rank">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.ControllComm.</span></span><span class="sig-name descname"><span class="pre">get_rank</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.get_rank" title="Link to this definition">¶</a></dt>
<dd><p>用于获得当前进程的全局进程号。例如你在第2个节点的第3个进程,每个节点5个进程,则返回7。</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>当前进程的进程号。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed.ControllComm</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_rank</span>

<span class="nb">print</span><span class="p">(</span><span class="n">get_rank</span><span class="p">())</span>
<span class="c1"># vqnetrun -n 2 python test.py</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="init-group">
<h3>init_group<a class="headerlink" href="#init-group" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ControllComm.init_group">
<span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.ControllComm.</span></span><span class="sig-name descname"><span class="pre">init_group</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rank_lists</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ControllComm.init_group" title="Link to this definition">¶</a></dt>
<dd><p>根据给出的进程数列表来对基于cpu下的进程组进行初始化。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>rank_lists</strong> – 通信进程组列表.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>初始化后的进程组列表。</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;mpi&quot;</span><span class="p">)</span>
<span class="n">num</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">group_l</span> <span class="o">=</span> <span class="n">init_group</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="k">for</span> <span class="n">comm_</span> <span class="ow">in</span> <span class="n">group_l</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span> <span class="ow">in</span> <span class="n">comm_</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">Comm_OP</span><span class="o">.</span><span class="n">allreduce_group</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">GroupComm</span> <span class="o">=</span> <span class="n">comm_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">Comm_OP</span><span class="o">.</span><span class="n">getRank</span><span class="p">()</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">num</span><span class="si">}</span><span class="s2"> after&quot;</span><span class="p">)</span>

<span class="c1"># vqnetrun -n 3 python test.py</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="pipelineparalleltrainingwrapper">
<h3>PipelineParallelTrainingWrapper<a class="headerlink" href="#pipelineparalleltrainingwrapper" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.pp.PipelineParallelTrainingWrapper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.pp.</span></span><span class="sig-name descname"><span class="pre">PipelineParallelTrainingWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainset</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.pp.PipelineParallelTrainingWrapper" title="Link to this definition">¶</a></dt>
<dd><p>Pipeline Parallel Training Wrapper 实现了 1F1B训练。仅在 Linux 平台上,且具有 GPU 的情况下可用。
更多算法细节可以在(<a class="reference external" href="https://www.deepspeed.ai/tutorials/pipeline/">https://www.deepspeed.ai/tutorials/pipeline/</a>)找到。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – 参数字典。参见示例。</p></li>
<li><p><strong>join_layers</strong> – Sequential 模块的列表。</p></li>
<li><p><strong>trainset</strong> – 数据集。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PipelineParallelTrainingWrapper 实例。</p>
</dd>
</dl>
<p>以下使用 CIFAR10数据库 <cite>CIFAR10_Dataset</cite>,在2块GPU上训练AlexNet上的分类任务。
本例子中分成两个流水线并行进程 <cite>pipeline_parallel_size</cite> = 2。
批处理大小为 <cite>train_batch_size</cite> = 64, 单GPU 上为 <cite>train_micro_batch_size_per_gpu</cite> = 32。
其他配置参数可见 <cite>args</cite>。
此外,每个进程需要在 <cite>__main__</cite> 函数中配置环境变量的 <cite>LOCAL_RANK</cite>。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">())</span>
</pre></div>
</div>
<p>调用 <cite>train_batch</cite> 进行训练。</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Module</span><span class="p">,</span><span class="n">Sequential</span><span class="p">,</span><span class="n">CrossEntropyLoss</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Linear</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">activation</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaxPool2D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">CrossEntropyLoss</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed.pp</span><span class="w"> </span><span class="kn">import</span> <span class="n">PipelineParallelTrainingWrapper</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed.pp</span><span class="w"> </span><span class="kn">import</span> <span class="n">comm</span> <span class="k">as</span> <span class="n">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>


<span class="n">pipeline_parallel_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">def</span><span class="w"> </span><span class="nf">cifar_trainset_vqnet</span><span class="p">(</span><span class="n">local_rank</span><span class="p">,</span> <span class="n">dl_path</span><span class="o">=</span><span class="s1">&#39;./cifar10-data&#39;</span><span class="p">):</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TransformCompose</span><span class="p">([</span>
        <span class="n">pyvqnet</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TransformResize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">pyvqnet</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TransformCenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">pyvqnet</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TransformToTensor</span><span class="p">(),</span>
        <span class="n">pyvqnet</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TransformNormalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
    <span class="p">])</span>

    <span class="n">trainset</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">CIFAR10_Dataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">dl_path</span><span class="p">,</span>
                                            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
                                            <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span><span class="n">layout</span><span class="o">=</span><span class="s2">&quot;HWC&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trainset</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>
        <span class="n">MaxPool2D</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>

        <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>
        <span class="n">MaxPool2D</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>

        <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>

        <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>

        <span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">output_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>
        <span class="n">MaxPool2D</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
        <span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">27</span> <span class="o">*</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>

        <span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
        <span class="n">F</span><span class="o">.</span><span class="n">ReLu</span><span class="p">(),</span>
        <span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">join_layers</span><span class="p">(</span><span class="n">vision_model</span><span class="p">):</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="o">*</span><span class="n">vision_model</span><span class="o">.</span><span class="n">features</span><span class="p">,</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="o">*</span><span class="n">vision_model</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">layers</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>


    <span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;backend&quot;</span><span class="p">:</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span>
    <span class="s2">&quot;train_batch_size&quot;</span> <span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span> <span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
<span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;Adam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span>
    <span class="p">}},</span>
    <span class="s2">&quot;local_rank&quot;</span><span class="p">:</span><span class="n">dist</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">(),</span>
    <span class="s2">&quot;pipeline_parallel_size&quot;</span><span class="p">:</span><span class="n">pipeline_parallel_size</span><span class="p">,</span> <span class="s2">&quot;seed&quot;</span><span class="p">:</span><span class="mi">42</span><span class="p">,</span> <span class="s2">&quot;steps&quot;</span><span class="p">:</span><span class="n">num_steps</span><span class="p">,</span>
    <span class="s2">&quot;loss&quot;</span><span class="p">:</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span>
    <span class="p">}</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">())</span>
    <span class="n">trainset</span> <span class="o">=</span> <span class="n">cifar_trainset_vqnet</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;local_rank&quot;</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">PipelineParallelTrainingWrapper</span><span class="p">(</span><span class="n">args</span><span class="p">,</span><span class="n">join_layers</span><span class="p">(</span><span class="n">Model</span><span class="p">()),</span><span class="n">trainset</span><span class="p">)</span>

    <span class="n">w</span><span class="o">.</span><span class="n">train_batch</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="zeromodelinitial">
<h3>ZeroModelInitial<a class="headerlink" href="#zeromodelinitial" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ZeroModelInitial">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.</span></span><span class="sig-name descname"><span class="pre">ZeroModelInitial</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ZeroModelInitial" title="Link to this definition">¶</a></dt>
<dd><p>Zero1 api接口, 目前仅用于linux平台下基于GPU并行计算。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – 参数字典。参见示例。</p></li>
<li><p><strong>model</strong> – 输入模型。</p></li>
<li><p><strong>optimizer</strong> – 优化器。</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Zero1 Engine.</p>
</dd>
</dl>
<p>以下使用 MNIST 数据库, 在2块GPU上训练一个MLP模型上的分类任务。</p>
<p>批处理大小为 <cite>train_batch_size</cite> = 64, <cite>zero_optimization</cite> 的阶段 <cite>stage</cite> 设置为1.
若Optimizer为None, 则采用 <cite>args</cite> 中 <cite>optimizer</cite> 的设置.
其他配置参数可见 <cite>args</cite>。
此外,每个进程需要在配置环境变量的 <cite>LOCAL_RANK</cite>。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">())</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">struct</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;training_data&quot;</span><span class="p">,</span>
            <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">path</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    load mnist data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">array</span><span class="w"> </span><span class="kn">import</span> <span class="n">array</span> <span class="k">as</span> <span class="n">pyarray</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;training_data&quot;</span><span class="p">:</span>
        <span class="n">fname_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;train-images.idx3-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="n">fname_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;train-labels.idx1-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;testing_data&quot;</span><span class="p">:</span>
        <span class="n">fname_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;t10k-images.idx3-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="n">fname_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;t10k-labels.idx1-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dataset must be &#39;training_data&#39; or &#39;testing_data&#39;&quot;</span><span class="p">)</span>

    <span class="n">flbl</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname_label</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;&gt;II&quot;</span><span class="p">,</span> <span class="n">flbl</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>

    <span class="n">lbl</span> <span class="o">=</span> <span class="n">pyarray</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">flbl</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="n">flbl</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">fimg</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname_image</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;&gt;IIII&quot;</span><span class="p">,</span> <span class="n">fimg</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">pyarray</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">fimg</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="n">fimg</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">ind</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="k">if</span> <span class="n">lbl</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="ow">in</span> <span class="n">digits</span><span class="p">]</span>
    <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)):</span>
        <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span><span class="p">:(</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">*</span>
                                <span class="n">cols</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lbl</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span>


<span class="n">train_images_np</span><span class="p">,</span> <span class="n">train_labels_np</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;training_data&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;../data/MNIST_data/&quot;</span><span class="p">)</span>
<span class="n">train_images_np</span> <span class="o">=</span> <span class="n">train_images_np</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">test_images_np</span><span class="p">,</span> <span class="n">test_labels_np</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;testing_data&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;../data/MNIST_data/&quot;</span><span class="p">)</span>
<span class="n">test_images_np</span> <span class="o">=</span> <span class="n">test_images_np</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">local_rank</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">ZeroModelInitial</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MNISTClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MNISTClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ac</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLu</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">QTensor</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ac</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MNISTClassifier</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">Comm_op</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
<span class="n">Comm_op</span><span class="o">.</span><span class="n">broadcast_model_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">args_</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span> <span class="c1"># 等效的总batch</span>
        <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;adam&quot;</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">}</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_local_rank</span><span class="p">())</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ZeroModelInitial</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args_</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">sums</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span>

<span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">time1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">num_batches</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_images_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>

        <span class="n">data_</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">train_images_np</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">kfloat32</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">train_labels_np</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">kint64</span><span class="p">)</span>

        <span class="n">data_</span> <span class="o">=</span> <span class="n">data_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data_</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="c1"># 基于返回的model做backward、step</span>
        <span class="n">model</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">compute_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train : rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2"> Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> acc </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

<span class="n">time2</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy of the model on the 10000 Train images: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">% time cost </span><span class="si">{</span><span class="n">time2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="columnparallellinear">
<h3>ColumnParallelLinear<a class="headerlink" href="#columnparallellinear" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.ColumnParallelLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.</span></span><span class="sig-name descname"><span class="pre">ColumnParallelLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_initializer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tp_comm</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.ColumnParallelLinear" title="Link to this definition">¶</a></dt>
<dd><p>张量并行计算,列并行线性层</p>
<p>线性层定义为 Y = XA + b。
其二维并行为 A = [A_1,…,A_p]。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 矩阵 A 的第一个维度。</p></li>
<li><p><strong>output_size</strong> – 矩阵 A 的第二个维度。</p></li>
<li><p><strong>weight_initializer</strong> – <cite>callable</cite> 默认为 <cite>normal</cite>。</p></li>
<li><p><strong>bias_initializer</strong> – <cite>callable</cite> 默认为0。</p></li>
<li><p><strong>use_bias</strong> – <cite>bool</cite> - 默认为 True。</p></li>
<li><p><strong>dtype</strong> – 默认 <cite>None</cite>,使用默认数据类型。</p></li>
<li><p><strong>name</strong> – 模块名称,默认为“”。</p></li>
<li><p><strong>tp_comm</strong> – 通讯控制器。</p></li>
</ul>
</dd>
</dl>
<p>以下使用 MNIST 数据库, 在2块GPU上训练一个MLP模型上的分类任务。</p>
<p>使用时与经典的Linear层的使用相似</p>
<p>多进程使用时基于 <cite>vqnetrun -n 2 python test.py</cite> 的方式进行</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed.tensor_parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">ColumnParallelLinear</span><span class="p">,</span> <span class="n">RowParallelLinear</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">time</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">struct</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;training_data&quot;</span><span class="p">,</span>
            <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">path</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    load mnist data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">array</span><span class="w"> </span><span class="kn">import</span> <span class="n">array</span> <span class="k">as</span> <span class="n">pyarray</span>
    <span class="c1"># download_mnist(path)</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;training_data&quot;</span><span class="p">:</span>
        <span class="n">fname_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="n">fname_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;train-labels-idx1-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;testing_data&quot;</span><span class="p">:</span>
        <span class="n">fname_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;t10k-images-idx3-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="n">fname_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;t10k-labels-idx1-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dataset must be &#39;training_data&#39; or &#39;testing_data&#39;&quot;</span><span class="p">)</span>

    <span class="n">flbl</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname_label</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;&gt;II&quot;</span><span class="p">,</span> <span class="n">flbl</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>

    <span class="n">lbl</span> <span class="o">=</span> <span class="n">pyarray</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">flbl</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="n">flbl</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">fimg</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname_image</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;&gt;IIII&quot;</span><span class="p">,</span> <span class="n">fimg</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">pyarray</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">fimg</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="n">fimg</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">ind</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="k">if</span> <span class="n">lbl</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="ow">in</span> <span class="n">digits</span><span class="p">]</span>
    <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)):</span>
        <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span><span class="p">:(</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">*</span>
                                <span class="n">cols</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lbl</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span>

<span class="n">train_images_np</span><span class="p">,</span> <span class="n">train_labels_np</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;training_data&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;./data/MNIST/raw/&quot;</span><span class="p">)</span>
<span class="n">train_images_np</span> <span class="o">=</span> <span class="n">train_images_np</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">test_images_np</span><span class="p">,</span> <span class="n">test_labels_np</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;testing_data&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;./data/MNIST/raw/&quot;</span><span class="p">)</span>
<span class="n">test_images_np</span> <span class="o">=</span> <span class="n">test_images_np</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">local_rank</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MNISTClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MNISTClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">RowParallelLinear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">ColumnParallelLinear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">RowParallelLinear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">ColumnParallelLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">RowParallelLinear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ac</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLu</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">QTensor</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ac</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">MNISTClassifier</span><span class="p">()</span>
<span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">Comm_OP</span><span class="o">.</span><span class="n">broadcast_model_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">sums</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span>

<span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">time1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_images_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">data_</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">train_images_np</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">kfloat32</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">train_labels_np</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">kint64</span><span class="p">)</span>

        <span class="n">data_</span> <span class="o">=</span> <span class="n">data_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data_</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">compute_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train : rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2"> Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> acc </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
<span class="n">time2</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy of the model on the 10000 Train images: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">% time cost </span><span class="si">{</span><span class="n">time2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="rowparallellinear">
<h3>RowParallelLinear<a class="headerlink" href="#rowparallellinear" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="pyvqnet.nn.pyvqnet.distributed.RowParallelLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyvqnet.distributed.</span></span><span class="sig-name descname"><span class="pre">RowParallelLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_initializer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_initializer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tp_comm</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyvqnet.nn.pyvqnet.distributed.RowParallelLinear" title="Link to this definition">¶</a></dt>
<dd><p>张量并行计算,行并行线性层。</p>
<p>线性层的定义为 Y = XA + b。A 沿其一维并行,X 沿其二维并行。
A = transpose([A_1 … A_p]) X = [X_1, …, X_p]。</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – 矩阵 A 的第一个维度。</p></li>
<li><p><strong>output_size</strong> – 矩阵 A 的第二个维度。</p></li>
<li><p><strong>weight_initializer</strong> – <cite>callable</cite> 默认为 <cite>normal</cite>。</p></li>
<li><p><strong>bias_initializer</strong> – <cite>callable</cite> 默认为0。</p></li>
<li><p><strong>use_bias</strong> – <cite>bool</cite> - 默认为 True。</p></li>
<li><p><strong>dtype</strong> – 默认 <cite>None</cite>,使用默认数据类型。</p></li>
<li><p><strong>name</strong> – 模块名称。</p></li>
<li><p><strong>tp_comm</strong> – 通讯控制器。</p></li>
</ul>
</dd>
</dl>
<p>以下使用 MNIST 数据库, 在2块GPU上训练一个MLP模型上的分类任务。
使用时与经典的Linear层的使用相似</p>
<p>多进程使用时基于 <cite>vqnetrun -n 2 python test.py</cite> 的方式进行</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed.tensor_parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">ColumnParallelLinear</span><span class="p">,</span> <span class="n">RowParallelLinear</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">time</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pyvqnet</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyvqnet</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="n">Comm_OP</span> <span class="o">=</span> <span class="n">CommController</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">struct</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;training_data&quot;</span><span class="p">,</span>
            <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">path</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    load mnist data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">array</span><span class="w"> </span><span class="kn">import</span> <span class="n">array</span> <span class="k">as</span> <span class="n">pyarray</span>
    <span class="c1"># download_mnist(path)</span>
    <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;training_data&quot;</span><span class="p">:</span>
        <span class="n">fname_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;train-images-idx3-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="n">fname_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;train-labels-idx1-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;testing_data&quot;</span><span class="p">:</span>
        <span class="n">fname_image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;t10k-images-idx3-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="n">fname_label</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;t10k-labels-idx1-ubyte&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
            <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;/&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dataset must be &#39;training_data&#39; or &#39;testing_data&#39;&quot;</span><span class="p">)</span>

    <span class="n">flbl</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname_label</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;&gt;II&quot;</span><span class="p">,</span> <span class="n">flbl</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>

    <span class="n">lbl</span> <span class="o">=</span> <span class="n">pyarray</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">flbl</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="n">flbl</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">fimg</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname_image</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;&gt;IIII&quot;</span><span class="p">,</span> <span class="n">fimg</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">pyarray</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">fimg</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    <span class="n">fimg</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">ind</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="k">if</span> <span class="n">lbl</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="ow">in</span> <span class="n">digits</span><span class="p">]</span>
    <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ind</span><span class="p">)):</span>
        <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">*</span> <span class="n">cols</span><span class="p">:(</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">rows</span> <span class="o">*</span>
                                <span class="n">cols</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">lbl</span><span class="p">[</span><span class="n">ind</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span>

<span class="n">train_images_np</span><span class="p">,</span> <span class="n">train_labels_np</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;training_data&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;./data/MNIST/raw/&quot;</span><span class="p">)</span>
<span class="n">train_images_np</span> <span class="o">=</span> <span class="n">train_images_np</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">test_images_np</span><span class="p">,</span> <span class="n">test_labels_np</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;testing_data&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span><span class="n">path</span><span class="o">=</span><span class="s2">&quot;./data/MNIST/raw/&quot;</span><span class="p">)</span>
<span class="n">test_images_np</span> <span class="o">=</span> <span class="n">test_images_np</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="n">local_rank</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MNISTClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MNISTClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">RowParallelLinear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">ColumnParallelLinear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">RowParallelLinear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">ColumnParallelLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">RowParallelLinear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">tp_comm</span> <span class="o">=</span> <span class="n">Comm_OP</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ac</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">ReLu</span><span class="p">()</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">pyvqnet</span><span class="o">.</span><span class="n">QTensor</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ac</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MNISTClassifier</span><span class="p">()</span>
<span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">Comm_OP</span><span class="o">.</span><span class="n">broadcast_model_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="n">pyvqnet</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">sums</span><span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span>

<span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">time1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_images_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
        <span class="n">data_</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">train_images_np</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">kfloat32</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="n">train_labels_np</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,:],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">kint64</span><span class="p">)</span>

        <span class="n">data_</span> <span class="o">=</span> <span class="n">data_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">+</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data_</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">compute_acc</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="n">total</span><span class="p">)</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train : rank </span><span class="si">{</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2"> Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">], step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> acc </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
<span class="n">time2</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy of the model on the 10000 Train images: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">% time cost </span><span class="si">{</span><span class="n">time2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="QTensor.html" class="btn btn-neutral float-left" title="QTensor 模块" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="utils.html" class="btn btn-neutral float-right" title="实用函数" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Original Quantum.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>